{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Extracting Base Estimators from Bagged Models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will have to make use of the attributes available with sklearn's [BaggingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html). In particular\n",
    "you will need to investigate what you can do with \n",
    "- `.base_estimator_`\n",
    "- `.estimators_`\n",
    "- `.estimators_samples_`\n",
    "- `.estimators_features_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Load-the-breast-cancer-data.\" data-toc-modified-id=\"1.-Load-the-breast-cancer-data.-1\">1. Load the breast cancer data.</a></span></li><li><span><a href=\"#2.-Load-required-sklearn-packages.\" data-toc-modified-id=\"2.-Load-required-sklearn-packages.-2\">2. Load required sklearn packages.</a></span></li><li><span><a href=\"#3.-Make-a-train-test-split.\" data-toc-modified-id=\"3.-Make-a-train-test-split.-3\">3. Make a train-test split.</a></span></li><li><span><a href=\"#4.-Create-and-fit-a-BaggingClassifier-with-a-DecisionTreeClassifier-base-estimator.\" data-toc-modified-id=\"4.-Create-and-fit-a-BaggingClassifier-with-a-DecisionTreeClassifier-base-estimator.-4\">4. Create and fit a <code>BaggingClassifier</code> with a <code>DecisionTreeClassifier</code> base estimator.</a></span></li><li><span><a href=\"#5.-Pull-out-the-base-estimator-from-the-ensemble-model.\" data-toc-modified-id=\"5.-Pull-out-the-base-estimator-from-the-ensemble-model.-5\">5. Pull out the base estimator from the ensemble model.</a></span></li><li><span><a href=\"#6.-Pull-out-all-the-base-estimators.\" data-toc-modified-id=\"6.-Pull-out-all-the-base-estimators.-6\">6. Pull out <em>all</em> the base estimators.</a></span></li><li><span><a href=\"#7.-Get-the-features-used-in-each-of-the-bagged-base-estimators.\" data-toc-modified-id=\"7.-Get-the-features-used-in-each-of-the-bagged-base-estimators.-7\">7. Get the features used in each of the bagged base estimators.</a></span></li><li><span><a href=\"#8.-Create-a-list-of-the-features-used-in-the-first-base-estimator.\" data-toc-modified-id=\"8.-Create-a-list-of-the-features-used-in-the-first-base-estimator.-8\">8. Create a list of the features used in the first base estimator.</a></span></li><li><span><a href=\"#9.-Get-out-the-samples-used-in-our-first-base-estimator.\" data-toc-modified-id=\"9.-Get-out-the-samples-used-in-our-first-base-estimator.-9\">9. Get out the samples used in our first base estimator.</a></span></li><li><span><a href=\"#10.-Get-out-the-target-subsample-for-the-estimator.\" data-toc-modified-id=\"10.-Get-out-the-target-subsample-for-the-estimator.-10\">10. Get out the target subsample for the estimator.</a></span></li><li><span><a href=\"#11.-Fit-a-decision-tree-equivalent-to-our-first-base-estimator.\" data-toc-modified-id=\"11.-Fit-a-decision-tree-equivalent-to-our-first-base-estimator.-11\">11. Fit a decision tree equivalent to our first base estimator.</a></span></li><li><span><a href=\"#12.-Bonus:-Take-each-of-the-decision-trees-from-the-ensemble-above-and-obtain-its-predictions-for-the-target-variable-in-the-test-set.-Use-majority-voting-to-obtain-the-ensemble-prediction-for-the-target-label.-Compare-with-the-bagging-classifier-score.\" data-toc-modified-id=\"12.-Bonus:-Take-each-of-the-decision-trees-from-the-ensemble-above-and-obtain-its-predictions-for-the-target-variable-in-the-test-set.-Use-majority-voting-to-obtain-the-ensemble-prediction-for-the-target-label.-Compare-with-the-bagging-classifier-score.-12\">12. Bonus: Take each of the decision trees from the ensemble above and obtain its predictions for the target variable in the test set. Use majority voting to obtain the ensemble prediction for the target label. Compare with the bagging classifier score.</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the breast cancer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Converting data into a dataframe structure \n",
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "# Setting up our Y value as well\n",
    "y = pd.Series(data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load required sklearn packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create and fit a `BaggingClassifier` with a `DecisionTreeClassifier` base estimator.\n",
    "\n",
    "- Fit on the training data.\n",
    "- Report the score on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT CV training score:\t 0.9223734177215188\n",
      "DT test score:\t 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "print(\"DT CV training score:\\t\", \n",
    "      cross_val_score(dt, X_train, y_train, cv=5,\n",
    "                    n_jobs=1).mean())\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"DT test score:\\t\", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Bagging CV training score:\t 0.9498734177215189\n",
      "DT bagging test score:\t 0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "bagging = BaggingClassifier(base_estimator=dt,\n",
    "                            max_samples=0.5, \n",
    "                            max_features=0.5, \n",
    "                            n_estimators=100)\n",
    "\n",
    "print(\"DT Bagging CV training score:\\t\", \n",
    "      cross_val_score(bagging, X_train, y_train,\n",
    "                    cv=5, n_jobs=1).mean())\n",
    "\n",
    "bagging.fit(X_train, y_train)\n",
    "print(\"DT bagging test score:\\t\", bagging.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Bagging CV training score:\t 0.957373417721519\n",
      "DT bagging test score:\t 0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "bagging = BaggingClassifier(base_estimator=dt,\n",
    "                            max_samples=1., \n",
    "                            max_features=1., \n",
    "                            n_estimators=100)\n",
    "\n",
    "print(\"DT Bagging CV training score:\\t\", \n",
    "      cross_val_score(bagging, X_train, y_train,\n",
    "                    cv=5, n_jobs=1).mean())\n",
    "\n",
    "bagging.fit(X_train, y_train)\n",
    "print(\"DT bagging test score:\\t\", bagging.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pull out the base estimator from the ensemble model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".base_estimator_\n",
    ".estimators_\n",
    ".estimators_samples_\n",
    ".estimators_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=424332229, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1914749643, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1835141394, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=98417145, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=929189261, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=808260120, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2139461151, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1715860405, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=22631017, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1046511508, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=969539910, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1919156039, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=172758946, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=96167259, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1236893860, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=547523312, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=901461447, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=658627916, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1160540740, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=97866564, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1248963729, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=668366174, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=547625093, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1651448452, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=238399990, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=488462641, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2121595558, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=636612335, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=275185408, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=545596440, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=915055986, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1347010437, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1823724650, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=362682806, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1834719343, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=552009877, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=588601041, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=766997796, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=430845135, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2084094397, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=627278567, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=785458724, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=49261544, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1155598798, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=496937492, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2120063792, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1667491764, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1744338100, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1000207876, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1119210861, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=563801050, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1239040185, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1330051996, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2039009502, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=217313488, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1756511272, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=914071843, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2018379231, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=109097587, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1854323437, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=582262846, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=704332429, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=596808254, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1345878882, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=876687927, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=385545009, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=476147321, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2042503178, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=705058312, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=20135329, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=101416687, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=915328687, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1506875997, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1268428800, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=638324275, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=69749113, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=294490686, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=291334604, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=339075263, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=465206562, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2106702347, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1991947395, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1269958316, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=764951413, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=136424836, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=874366742, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1986360896, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1271208245, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=865898164, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1579022428, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1223115805, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1945098738, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=92469637, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1018659447, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1123020391, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=274818366, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=648155859, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=336408769, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1272174325, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=65169892, splitter='best')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pull out *all* the base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.base_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Get the features used in each of the bagged base estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".base_estimator_\n",
    ".estimators_\n",
    ".estimators_samples_\n",
    ".estimators_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.estimators_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create a list of the features used in the first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False,\n",
       "            random_state=424332229, splitter='best')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.estimators_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Get out the samples used in our first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.estimators_samples_[0]\n",
    "len(bagging.estimators_samples_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Get out the target subsample for the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412    1\n",
       "427    1\n",
       "144    1\n",
       "64     0\n",
       "368    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.iloc[bagging.estimators_samples_[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Fit a decision tree equivalent to our first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = X.loc[ bagging.estimators_samples_[0],['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "       'smoothness error', 'compactness error', 'concavity error',\n",
    "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "       'worst concave points', 'worst symmetry']  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>12.360</td>\n",
       "      <td>18.54</td>\n",
       "      <td>79.01</td>\n",
       "      <td>466.7</td>\n",
       "      <td>0.08477</td>\n",
       "      <td>0.06815</td>\n",
       "      <td>0.026430</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.1602</td>\n",
       "      <td>0.06066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>13.290</td>\n",
       "      <td>27.49</td>\n",
       "      <td>85.56</td>\n",
       "      <td>544.1</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.19630</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.084420</td>\n",
       "      <td>0.2983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>12.310</td>\n",
       "      <td>16.52</td>\n",
       "      <td>79.19</td>\n",
       "      <td>470.9</td>\n",
       "      <td>0.09172</td>\n",
       "      <td>0.06829</td>\n",
       "      <td>0.033720</td>\n",
       "      <td>0.022720</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>14.110</td>\n",
       "      <td>23.21</td>\n",
       "      <td>89.71</td>\n",
       "      <td>611.1</td>\n",
       "      <td>0.11760</td>\n",
       "      <td>0.18430</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.2618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>12.460</td>\n",
       "      <td>19.89</td>\n",
       "      <td>80.43</td>\n",
       "      <td>471.3</td>\n",
       "      <td>0.08451</td>\n",
       "      <td>0.10140</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.030990</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.06249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>13.460</td>\n",
       "      <td>23.07</td>\n",
       "      <td>88.13</td>\n",
       "      <td>551.3</td>\n",
       "      <td>0.10500</td>\n",
       "      <td>0.21580</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.076250</td>\n",
       "      <td>0.2685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.025620</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.05863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>13.300</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.048330</td>\n",
       "      <td>0.050130</td>\n",
       "      <td>0.1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.05699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>21.310</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>0.21170</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.2341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>12.340</td>\n",
       "      <td>22.22</td>\n",
       "      <td>79.85</td>\n",
       "      <td>464.5</td>\n",
       "      <td>0.10120</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.028220</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.06761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>13.580</td>\n",
       "      <td>28.68</td>\n",
       "      <td>87.36</td>\n",
       "      <td>553.0</td>\n",
       "      <td>0.14520</td>\n",
       "      <td>0.23380</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.081940</td>\n",
       "      <td>0.2268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>10.480</td>\n",
       "      <td>19.86</td>\n",
       "      <td>66.72</td>\n",
       "      <td>337.7</td>\n",
       "      <td>0.10700</td>\n",
       "      <td>0.05971</td>\n",
       "      <td>0.048310</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.06440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>11.480</td>\n",
       "      <td>29.46</td>\n",
       "      <td>73.68</td>\n",
       "      <td>402.8</td>\n",
       "      <td>0.15150</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>0.2883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>17.950</td>\n",
       "      <td>20.01</td>\n",
       "      <td>114.20</td>\n",
       "      <td>982.0</td>\n",
       "      <td>0.08402</td>\n",
       "      <td>0.06722</td>\n",
       "      <td>0.072930</td>\n",
       "      <td>0.055960</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.05025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>20.580</td>\n",
       "      <td>27.83</td>\n",
       "      <td>129.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.12020</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.4882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>21.090</td>\n",
       "      <td>26.57</td>\n",
       "      <td>142.70</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.248700</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>0.07398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>26.680</td>\n",
       "      <td>33.48</td>\n",
       "      <td>176.50</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.75840</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.4098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.072830</td>\n",
       "      <td>0.3184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>17.420</td>\n",
       "      <td>25.56</td>\n",
       "      <td>114.50</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.10060</td>\n",
       "      <td>0.11460</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.065970</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.05866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>18.070</td>\n",
       "      <td>28.07</td>\n",
       "      <td>120.40</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.12430</td>\n",
       "      <td>0.17930</td>\n",
       "      <td>0.280300</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>11.800</td>\n",
       "      <td>16.58</td>\n",
       "      <td>78.99</td>\n",
       "      <td>432.0</td>\n",
       "      <td>0.10910</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.074150</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.07371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>13.740</td>\n",
       "      <td>26.38</td>\n",
       "      <td>91.93</td>\n",
       "      <td>591.7</td>\n",
       "      <td>0.13850</td>\n",
       "      <td>0.40920</td>\n",
       "      <td>0.450400</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.5774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>16.270</td>\n",
       "      <td>20.71</td>\n",
       "      <td>106.90</td>\n",
       "      <td>813.7</td>\n",
       "      <td>0.11690</td>\n",
       "      <td>0.13190</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.084880</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.06277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>19.280</td>\n",
       "      <td>30.38</td>\n",
       "      <td>129.80</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>0.15900</td>\n",
       "      <td>0.29470</td>\n",
       "      <td>0.359700</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>0.3103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>15.460</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.080870</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.05796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>19.260</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.23940</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>0.2837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>15.270</td>\n",
       "      <td>12.91</td>\n",
       "      <td>98.17</td>\n",
       "      <td>725.5</td>\n",
       "      <td>0.08182</td>\n",
       "      <td>0.06230</td>\n",
       "      <td>0.058920</td>\n",
       "      <td>0.031570</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.05526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>17.380</td>\n",
       "      <td>15.92</td>\n",
       "      <td>113.70</td>\n",
       "      <td>932.7</td>\n",
       "      <td>0.12220</td>\n",
       "      <td>0.21860</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.2320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>10.800</td>\n",
       "      <td>9.71</td>\n",
       "      <td>68.77</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.09594</td>\n",
       "      <td>0.05736</td>\n",
       "      <td>0.025310</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.06400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>11.600</td>\n",
       "      <td>12.02</td>\n",
       "      <td>73.66</td>\n",
       "      <td>414.0</td>\n",
       "      <td>0.14360</td>\n",
       "      <td>0.12570</td>\n",
       "      <td>0.104700</td>\n",
       "      <td>0.046030</td>\n",
       "      <td>0.2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>11.710</td>\n",
       "      <td>17.19</td>\n",
       "      <td>74.68</td>\n",
       "      <td>420.3</td>\n",
       "      <td>0.09774</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>0.032390</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.06095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>13.010</td>\n",
       "      <td>21.39</td>\n",
       "      <td>84.42</td>\n",
       "      <td>521.5</td>\n",
       "      <td>0.13230</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.2572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>10.260</td>\n",
       "      <td>14.71</td>\n",
       "      <td>66.20</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09882</td>\n",
       "      <td>0.09159</td>\n",
       "      <td>0.035810</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.07005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>10.880</td>\n",
       "      <td>19.48</td>\n",
       "      <td>70.89</td>\n",
       "      <td>357.1</td>\n",
       "      <td>0.13600</td>\n",
       "      <td>0.16360</td>\n",
       "      <td>0.071620</td>\n",
       "      <td>0.040740</td>\n",
       "      <td>0.2434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9.173</td>\n",
       "      <td>13.86</td>\n",
       "      <td>59.20</td>\n",
       "      <td>260.9</td>\n",
       "      <td>0.07721</td>\n",
       "      <td>0.08751</td>\n",
       "      <td>0.059880</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.06963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>10.010</td>\n",
       "      <td>19.23</td>\n",
       "      <td>65.59</td>\n",
       "      <td>310.1</td>\n",
       "      <td>0.09836</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>0.050870</td>\n",
       "      <td>0.3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>16.170</td>\n",
       "      <td>16.07</td>\n",
       "      <td>106.30</td>\n",
       "      <td>788.5</td>\n",
       "      <td>0.09880</td>\n",
       "      <td>0.14380</td>\n",
       "      <td>0.066510</td>\n",
       "      <td>0.053970</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.06572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>16.970</td>\n",
       "      <td>19.14</td>\n",
       "      <td>113.10</td>\n",
       "      <td>861.5</td>\n",
       "      <td>0.12350</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.3153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>20.340</td>\n",
       "      <td>21.51</td>\n",
       "      <td>135.90</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.256500</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.2569</td>\n",
       "      <td>0.06670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>25.300</td>\n",
       "      <td>31.86</td>\n",
       "      <td>171.10</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>0.15920</td>\n",
       "      <td>0.44920</td>\n",
       "      <td>0.534400</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.5558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>9.904</td>\n",
       "      <td>18.06</td>\n",
       "      <td>64.60</td>\n",
       "      <td>302.4</td>\n",
       "      <td>0.09699</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.037160</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.08116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017920</td>\n",
       "      <td>11.260</td>\n",
       "      <td>24.39</td>\n",
       "      <td>73.07</td>\n",
       "      <td>390.2</td>\n",
       "      <td>0.13010</td>\n",
       "      <td>0.29500</td>\n",
       "      <td>0.348600</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.2614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>15.100</td>\n",
       "      <td>22.02</td>\n",
       "      <td>97.26</td>\n",
       "      <td>712.8</td>\n",
       "      <td>0.09056</td>\n",
       "      <td>0.07081</td>\n",
       "      <td>0.052530</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>0.1616</td>\n",
       "      <td>0.05684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>18.100</td>\n",
       "      <td>31.69</td>\n",
       "      <td>117.70</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.20570</td>\n",
       "      <td>0.271200</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>18.220</td>\n",
       "      <td>18.70</td>\n",
       "      <td>120.30</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.14850</td>\n",
       "      <td>0.177200</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.2092</td>\n",
       "      <td>0.06310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>20.600</td>\n",
       "      <td>24.13</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>0.22970</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.3021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>11.640</td>\n",
       "      <td>18.33</td>\n",
       "      <td>75.17</td>\n",
       "      <td>412.5</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.034850</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.06520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>13.140</td>\n",
       "      <td>29.26</td>\n",
       "      <td>85.51</td>\n",
       "      <td>521.7</td>\n",
       "      <td>0.16880</td>\n",
       "      <td>0.26600</td>\n",
       "      <td>0.287300</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.2806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>19.160</td>\n",
       "      <td>26.60</td>\n",
       "      <td>126.20</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.10200</td>\n",
       "      <td>0.14530</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.096640</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.06220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>23.720</td>\n",
       "      <td>35.90</td>\n",
       "      <td>159.80</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>0.17820</td>\n",
       "      <td>0.38410</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.3258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>12.490</td>\n",
       "      <td>16.85</td>\n",
       "      <td>79.19</td>\n",
       "      <td>481.6</td>\n",
       "      <td>0.08511</td>\n",
       "      <td>0.03834</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.05673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>13.340</td>\n",
       "      <td>19.71</td>\n",
       "      <td>84.48</td>\n",
       "      <td>544.2</td>\n",
       "      <td>0.11040</td>\n",
       "      <td>0.04953</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.027840</td>\n",
       "      <td>0.1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>12.360</td>\n",
       "      <td>18.54</td>\n",
       "      <td>79.01</td>\n",
       "      <td>466.7</td>\n",
       "      <td>0.08477</td>\n",
       "      <td>0.06815</td>\n",
       "      <td>0.026430</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.1602</td>\n",
       "      <td>0.06066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>13.290</td>\n",
       "      <td>27.49</td>\n",
       "      <td>85.56</td>\n",
       "      <td>544.1</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.19630</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.084420</td>\n",
       "      <td>0.2983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>14.450</td>\n",
       "      <td>20.22</td>\n",
       "      <td>94.49</td>\n",
       "      <td>642.7</td>\n",
       "      <td>0.09872</td>\n",
       "      <td>0.12060</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.06466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>18.330</td>\n",
       "      <td>30.12</td>\n",
       "      <td>117.90</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>0.15520</td>\n",
       "      <td>0.40560</td>\n",
       "      <td>0.496700</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.4753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>14.480</td>\n",
       "      <td>21.46</td>\n",
       "      <td>94.25</td>\n",
       "      <td>648.2</td>\n",
       "      <td>0.09444</td>\n",
       "      <td>0.09947</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>0.049380</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.05636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>16.210</td>\n",
       "      <td>29.25</td>\n",
       "      <td>108.40</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.13060</td>\n",
       "      <td>0.19760</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>12.180</td>\n",
       "      <td>14.08</td>\n",
       "      <td>77.25</td>\n",
       "      <td>461.4</td>\n",
       "      <td>0.07734</td>\n",
       "      <td>0.03212</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.05649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>12.850</td>\n",
       "      <td>16.47</td>\n",
       "      <td>81.60</td>\n",
       "      <td>513.1</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.05332</td>\n",
       "      <td>0.041160</td>\n",
       "      <td>0.018520</td>\n",
       "      <td>0.2293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>11.520</td>\n",
       "      <td>18.75</td>\n",
       "      <td>73.34</td>\n",
       "      <td>409.0</td>\n",
       "      <td>0.09524</td>\n",
       "      <td>0.05473</td>\n",
       "      <td>0.030360</td>\n",
       "      <td>0.022780</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.05907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>12.840</td>\n",
       "      <td>22.47</td>\n",
       "      <td>81.81</td>\n",
       "      <td>506.2</td>\n",
       "      <td>0.12490</td>\n",
       "      <td>0.08720</td>\n",
       "      <td>0.090760</td>\n",
       "      <td>0.063160</td>\n",
       "      <td>0.3306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>20.310</td>\n",
       "      <td>27.06</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1288.0</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10880</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.093330</td>\n",
       "      <td>0.1814</td>\n",
       "      <td>0.05572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>24.330</td>\n",
       "      <td>39.16</td>\n",
       "      <td>162.30</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>0.15220</td>\n",
       "      <td>0.29450</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.3151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>8.888</td>\n",
       "      <td>14.64</td>\n",
       "      <td>58.79</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.09783</td>\n",
       "      <td>0.15310</td>\n",
       "      <td>0.086060</td>\n",
       "      <td>0.028720</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.08980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>9.733</td>\n",
       "      <td>15.67</td>\n",
       "      <td>62.56</td>\n",
       "      <td>284.4</td>\n",
       "      <td>0.12070</td>\n",
       "      <td>0.24360</td>\n",
       "      <td>0.143400</td>\n",
       "      <td>0.047860</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>12.770</td>\n",
       "      <td>21.41</td>\n",
       "      <td>82.02</td>\n",
       "      <td>507.4</td>\n",
       "      <td>0.08749</td>\n",
       "      <td>0.06601</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>0.028640</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>13.750</td>\n",
       "      <td>23.50</td>\n",
       "      <td>89.04</td>\n",
       "      <td>579.5</td>\n",
       "      <td>0.09388</td>\n",
       "      <td>0.08978</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.047730</td>\n",
       "      <td>0.2179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>9.465</td>\n",
       "      <td>21.01</td>\n",
       "      <td>60.11</td>\n",
       "      <td>269.4</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>0.021720</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.06899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>10.410</td>\n",
       "      <td>31.56</td>\n",
       "      <td>67.03</td>\n",
       "      <td>330.7</td>\n",
       "      <td>0.15480</td>\n",
       "      <td>0.16640</td>\n",
       "      <td>0.094120</td>\n",
       "      <td>0.065170</td>\n",
       "      <td>0.2878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.05278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>29.170</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.315500</td>\n",
       "      <td>0.200900</td>\n",
       "      <td>0.2822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>11.750</td>\n",
       "      <td>20.18</td>\n",
       "      <td>76.10</td>\n",
       "      <td>419.8</td>\n",
       "      <td>0.10890</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.068430</td>\n",
       "      <td>0.037380</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>0.06453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>13.320</td>\n",
       "      <td>26.21</td>\n",
       "      <td>88.91</td>\n",
       "      <td>543.9</td>\n",
       "      <td>0.13580</td>\n",
       "      <td>0.18920</td>\n",
       "      <td>0.195600</td>\n",
       "      <td>0.079090</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.05697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>19.190</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.15510</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.099750</td>\n",
       "      <td>0.2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>14.500</td>\n",
       "      <td>10.89</td>\n",
       "      <td>94.28</td>\n",
       "      <td>640.7</td>\n",
       "      <td>0.11010</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.088420</td>\n",
       "      <td>0.057780</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.06402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>15.700</td>\n",
       "      <td>15.98</td>\n",
       "      <td>102.80</td>\n",
       "      <td>745.5</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.17880</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.2889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>11.080</td>\n",
       "      <td>14.71</td>\n",
       "      <td>70.21</td>\n",
       "      <td>372.7</td>\n",
       "      <td>0.10060</td>\n",
       "      <td>0.05743</td>\n",
       "      <td>0.023630</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>11.350</td>\n",
       "      <td>16.82</td>\n",
       "      <td>72.01</td>\n",
       "      <td>396.5</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.08240</td>\n",
       "      <td>0.039380</td>\n",
       "      <td>0.043060</td>\n",
       "      <td>0.1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>12.580</td>\n",
       "      <td>18.40</td>\n",
       "      <td>79.83</td>\n",
       "      <td>489.0</td>\n",
       "      <td>0.08393</td>\n",
       "      <td>0.04216</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.05855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>13.500</td>\n",
       "      <td>23.08</td>\n",
       "      <td>85.56</td>\n",
       "      <td>564.1</td>\n",
       "      <td>0.10380</td>\n",
       "      <td>0.06624</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>19.100</td>\n",
       "      <td>26.29</td>\n",
       "      <td>129.10</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>0.12150</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.07224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>20.330</td>\n",
       "      <td>32.72</td>\n",
       "      <td>141.30</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>0.13920</td>\n",
       "      <td>0.28170</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>15.700</td>\n",
       "      <td>20.31</td>\n",
       "      <td>101.20</td>\n",
       "      <td>766.6</td>\n",
       "      <td>0.09597</td>\n",
       "      <td>0.08799</td>\n",
       "      <td>0.065930</td>\n",
       "      <td>0.051890</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.05549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>20.110</td>\n",
       "      <td>32.82</td>\n",
       "      <td>129.30</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0.14140</td>\n",
       "      <td>0.35470</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.3437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>15.280</td>\n",
       "      <td>22.41</td>\n",
       "      <td>98.92</td>\n",
       "      <td>710.6</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.053750</td>\n",
       "      <td>0.032630</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.06317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>17.800</td>\n",
       "      <td>28.03</td>\n",
       "      <td>113.80</td>\n",
       "      <td>973.1</td>\n",
       "      <td>0.13010</td>\n",
       "      <td>0.32990</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>11.710</td>\n",
       "      <td>17.19</td>\n",
       "      <td>74.68</td>\n",
       "      <td>420.3</td>\n",
       "      <td>0.09774</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>0.032390</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.06095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>13.010</td>\n",
       "      <td>21.39</td>\n",
       "      <td>84.42</td>\n",
       "      <td>521.5</td>\n",
       "      <td>0.13230</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.2572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>13.270</td>\n",
       "      <td>17.02</td>\n",
       "      <td>84.55</td>\n",
       "      <td>546.4</td>\n",
       "      <td>0.08445</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.035540</td>\n",
       "      <td>0.024560</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.05674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>15.140</td>\n",
       "      <td>23.60</td>\n",
       "      <td>98.84</td>\n",
       "      <td>708.8</td>\n",
       "      <td>0.12760</td>\n",
       "      <td>0.13110</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.096780</td>\n",
       "      <td>0.2506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>18.810</td>\n",
       "      <td>19.98</td>\n",
       "      <td>120.90</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>0.08923</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.058430</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.04996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>19.960</td>\n",
       "      <td>24.30</td>\n",
       "      <td>129.00</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>0.12430</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.2567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>10.050</td>\n",
       "      <td>17.53</td>\n",
       "      <td>64.41</td>\n",
       "      <td>310.8</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.07326</td>\n",
       "      <td>0.025110</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.06331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>11.160</td>\n",
       "      <td>26.84</td>\n",
       "      <td>71.98</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.14020</td>\n",
       "      <td>0.14020</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>0.064990</td>\n",
       "      <td>0.2894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>10.490</td>\n",
       "      <td>18.61</td>\n",
       "      <td>66.86</td>\n",
       "      <td>334.3</td>\n",
       "      <td>0.10680</td>\n",
       "      <td>0.06678</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.06600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>11.060</td>\n",
       "      <td>24.54</td>\n",
       "      <td>70.76</td>\n",
       "      <td>375.4</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.084230</td>\n",
       "      <td>0.065280</td>\n",
       "      <td>0.2213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>9.876</td>\n",
       "      <td>17.27</td>\n",
       "      <td>62.92</td>\n",
       "      <td>295.4</td>\n",
       "      <td>0.10890</td>\n",
       "      <td>0.07232</td>\n",
       "      <td>0.017560</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.06285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>10.420</td>\n",
       "      <td>23.22</td>\n",
       "      <td>67.08</td>\n",
       "      <td>331.6</td>\n",
       "      <td>0.14150</td>\n",
       "      <td>0.12470</td>\n",
       "      <td>0.062130</td>\n",
       "      <td>0.055880</td>\n",
       "      <td>0.2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.180</td>\n",
       "      <td>20.52</td>\n",
       "      <td>77.22</td>\n",
       "      <td>458.7</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.04038</td>\n",
       "      <td>0.023830</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.05677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>13.340</td>\n",
       "      <td>32.84</td>\n",
       "      <td>84.58</td>\n",
       "      <td>547.8</td>\n",
       "      <td>0.11230</td>\n",
       "      <td>0.08862</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.074310</td>\n",
       "      <td>0.2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.073640</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>0.07077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>17.460</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.65770</td>\n",
       "      <td>0.702600</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.4218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>13.640</td>\n",
       "      <td>16.34</td>\n",
       "      <td>87.21</td>\n",
       "      <td>571.8</td>\n",
       "      <td>0.07685</td>\n",
       "      <td>0.06059</td>\n",
       "      <td>0.018570</td>\n",
       "      <td>0.017230</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.05953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>14.670</td>\n",
       "      <td>23.19</td>\n",
       "      <td>96.08</td>\n",
       "      <td>656.7</td>\n",
       "      <td>0.10890</td>\n",
       "      <td>0.15820</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.085860</td>\n",
       "      <td>0.2346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>13.440</td>\n",
       "      <td>21.58</td>\n",
       "      <td>86.18</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.08162</td>\n",
       "      <td>0.06031</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>0.05587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>15.930</td>\n",
       "      <td>30.25</td>\n",
       "      <td>102.50</td>\n",
       "      <td>787.9</td>\n",
       "      <td>0.10940</td>\n",
       "      <td>0.20430</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16.740</td>\n",
       "      <td>21.59</td>\n",
       "      <td>110.10</td>\n",
       "      <td>869.5</td>\n",
       "      <td>0.09610</td>\n",
       "      <td>0.13360</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.060180</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>0.05656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>20.010</td>\n",
       "      <td>29.02</td>\n",
       "      <td>133.50</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>0.15630</td>\n",
       "      <td>0.38350</td>\n",
       "      <td>0.540900</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.4863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>11.430</td>\n",
       "      <td>17.31</td>\n",
       "      <td>73.66</td>\n",
       "      <td>398.0</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.09486</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.018610</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.06562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>12.780</td>\n",
       "      <td>26.76</td>\n",
       "      <td>82.66</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.17920</td>\n",
       "      <td>0.077080</td>\n",
       "      <td>0.064020</td>\n",
       "      <td>0.2584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>13.150</td>\n",
       "      <td>15.34</td>\n",
       "      <td>85.31</td>\n",
       "      <td>538.9</td>\n",
       "      <td>0.09384</td>\n",
       "      <td>0.08498</td>\n",
       "      <td>0.092930</td>\n",
       "      <td>0.034830</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.06207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>14.770</td>\n",
       "      <td>20.50</td>\n",
       "      <td>97.67</td>\n",
       "      <td>677.3</td>\n",
       "      <td>0.14780</td>\n",
       "      <td>0.22560</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.097220</td>\n",
       "      <td>0.3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>12.340</td>\n",
       "      <td>26.86</td>\n",
       "      <td>81.15</td>\n",
       "      <td>477.4</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.13530</td>\n",
       "      <td>0.108500</td>\n",
       "      <td>0.045620</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.06937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>15.650</td>\n",
       "      <td>39.34</td>\n",
       "      <td>101.70</td>\n",
       "      <td>768.9</td>\n",
       "      <td>0.17850</td>\n",
       "      <td>0.47060</td>\n",
       "      <td>0.442500</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>8.597</td>\n",
       "      <td>18.60</td>\n",
       "      <td>54.09</td>\n",
       "      <td>221.2</td>\n",
       "      <td>0.10740</td>\n",
       "      <td>0.05847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2163</td>\n",
       "      <td>0.07359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>8.952</td>\n",
       "      <td>22.44</td>\n",
       "      <td>56.65</td>\n",
       "      <td>240.1</td>\n",
       "      <td>0.13470</td>\n",
       "      <td>0.07767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "107       12.360         18.54           79.01      466.7          0.08477   \n",
       "74        12.310         16.52           79.19      470.9          0.09172   \n",
       "301       12.460         19.89           80.43      471.3          0.08451   \n",
       "37        13.030         18.42           82.61      523.8          0.08983   \n",
       "27        18.610         20.25          122.10     1094.0          0.09440   \n",
       "163       12.340         22.22           79.85      464.5          0.10120   \n",
       "245       10.480         19.86           66.72      337.7          0.10700   \n",
       "119       17.950         20.01          114.20      982.0          0.08402   \n",
       "181       21.090         26.57          142.70     1311.0          0.11410   \n",
       "20        13.080         15.71           85.63      520.0          0.10750   \n",
       "213       17.420         25.56          114.50      948.0          0.10060   \n",
       "146       11.800         16.58           78.99      432.0          0.10910   \n",
       "328       16.270         20.71          106.90      813.7          0.11690   \n",
       "131       15.460         19.48          101.70      748.9          0.10920   \n",
       "209       15.270         12.91           98.17      725.5          0.08182   \n",
       "166       10.800          9.71           68.77      357.6          0.09594   \n",
       "187       11.710         17.19           74.68      420.3          0.09774   \n",
       "345       10.260         14.71           66.20      321.6          0.09882   \n",
       "63         9.173         13.86           59.20      260.9          0.07721   \n",
       "375       16.170         16.07          106.30      788.5          0.09880   \n",
       "323       20.340         21.51          135.90     1264.0          0.11700   \n",
       "176        9.904         18.06           64.60      302.4          0.09699   \n",
       "54        15.100         22.02           97.26      712.8          0.09056   \n",
       "53        18.220         18.70          120.30     1033.0          0.11480   \n",
       "106       11.640         18.33           75.17      412.5          0.11420   \n",
       "280       19.160         26.60          126.20     1138.0          0.10200   \n",
       "315       12.490         16.85           79.19      481.6          0.08511   \n",
       "107       12.360         18.54           79.01      466.7          0.08477   \n",
       "199       14.450         20.22           94.49      642.7          0.09872   \n",
       "86        14.480         21.46           94.25      648.2          0.09444   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "316       12.180         14.08           77.25      461.4          0.07734   \n",
       "55        11.520         18.75           73.34      409.0          0.09524   \n",
       "260       20.310         27.06          132.90     1288.0          0.10000   \n",
       "71         8.888         14.64           58.79      244.0          0.09783   \n",
       "191       12.770         21.41           82.02      507.4          0.08749   \n",
       "66         9.465         21.01           60.11      269.4          0.10440   \n",
       "23        21.160         23.04          137.20     1404.0          0.09428   \n",
       "160       11.750         20.18           76.10      419.8          0.10890   \n",
       "10        16.020         23.24          102.70      797.8          0.08206   \n",
       "123       14.500         10.89           94.28      640.7          0.11010   \n",
       "173       11.080         14.71           70.21      372.7          0.10060   \n",
       "285       12.580         18.40           79.83      489.0          0.08393   \n",
       "83        19.100         26.29          129.10     1132.0          0.12150   \n",
       "182       15.700         20.31          101.20      766.6          0.09597   \n",
       "184       15.280         22.41           98.92      710.6          0.09057   \n",
       "187       11.710         17.19           74.68      420.3          0.09774   \n",
       "224       13.270         17.02           84.55      546.4          0.08445   \n",
       "277       18.810         19.98          120.90     1102.0          0.08923   \n",
       "338       10.050         17.53           64.41      310.8          0.10070   \n",
       "303       10.490         18.61           66.86      334.3          0.10680   \n",
       "206        9.876         17.27           62.92      295.4          0.10890   \n",
       "102       12.180         20.52           77.22      458.7          0.08013   \n",
       "15        14.540         27.54           96.73      658.8          0.11390   \n",
       "51        13.640         16.34           87.21      571.8          0.07685   \n",
       "40        13.440         21.58           86.18      563.0          0.08162   \n",
       "35        16.740         21.59          110.10      869.5          0.09610   \n",
       "142       11.430         17.31           73.66      398.0          0.10920   \n",
       "154       13.150         15.34           85.31      538.9          0.09384   \n",
       "193       12.340         26.86           81.15      477.4          0.10340   \n",
       "314        8.597         18.60           54.09      221.2          0.10740   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "107           0.06815        0.026430             0.019210         0.1602   \n",
       "74            0.06829        0.033720             0.022720         0.1720   \n",
       "301           0.10140        0.068300             0.030990         0.1781   \n",
       "37            0.03766        0.025620             0.029230         0.1467   \n",
       "27            0.10660        0.149000             0.077310         0.1697   \n",
       "163           0.10150        0.053700             0.028220         0.1551   \n",
       "245           0.05971        0.048310             0.030700         0.1737   \n",
       "119           0.06722        0.072930             0.055960         0.2129   \n",
       "181           0.28320        0.248700             0.149600         0.2395   \n",
       "20            0.12700        0.045680             0.031100         0.1967   \n",
       "213           0.11460        0.168200             0.065970         0.1308   \n",
       "146           0.17000        0.165900             0.074150         0.2678   \n",
       "328           0.13190        0.147800             0.084880         0.1948   \n",
       "131           0.12230        0.146600             0.080870         0.1931   \n",
       "209           0.06230        0.058920             0.031570         0.1359   \n",
       "166           0.05736        0.025310             0.016980         0.1381   \n",
       "187           0.06141        0.038090             0.032390         0.1516   \n",
       "345           0.09159        0.035810             0.020370         0.1633   \n",
       "63            0.08751        0.059880             0.021800         0.2341   \n",
       "375           0.14380        0.066510             0.053970         0.1990   \n",
       "323           0.18750        0.256500             0.150400         0.2569   \n",
       "176           0.12940        0.130700             0.037160         0.1669   \n",
       "54            0.07081        0.052530             0.033340         0.1616   \n",
       "53            0.14850        0.177200             0.106000         0.2092   \n",
       "106           0.10170        0.070700             0.034850         0.1801   \n",
       "280           0.14530        0.192100             0.096640         0.1902   \n",
       "315           0.03834        0.004473             0.006423         0.1215   \n",
       "107           0.06815        0.026430             0.019210         0.1602   \n",
       "199           0.12060        0.118000             0.059800         0.1950   \n",
       "86            0.09947        0.120400             0.049380         0.2075   \n",
       "..                ...             ...                  ...            ...   \n",
       "316           0.03212        0.011230             0.005051         0.1673   \n",
       "55            0.05473        0.030360             0.022780         0.1920   \n",
       "260           0.10880        0.151900             0.093330         0.1814   \n",
       "71            0.15310        0.086060             0.028720         0.1902   \n",
       "191           0.06601        0.031120             0.028640         0.1694   \n",
       "66            0.07773        0.021720             0.015040         0.1717   \n",
       "23            0.10220        0.109700             0.086320         0.1769   \n",
       "160           0.11410        0.068430             0.037380         0.1993   \n",
       "10            0.06669        0.032990             0.033230         0.1528   \n",
       "123           0.10990        0.088420             0.057780         0.1856   \n",
       "173           0.05743        0.023630             0.025830         0.1566   \n",
       "285           0.04216        0.001860             0.002924         0.1697   \n",
       "83            0.17910        0.193700             0.146900         0.1634   \n",
       "182           0.08799        0.065930             0.051890         0.1618   \n",
       "184           0.10520        0.053750             0.032630         0.1727   \n",
       "187           0.06141        0.038090             0.032390         0.1516   \n",
       "224           0.04994        0.035540             0.024560         0.1496   \n",
       "277           0.05884        0.080200             0.058430         0.1550   \n",
       "338           0.07326        0.025110             0.017750         0.1890   \n",
       "303           0.06678        0.022970             0.017800         0.1482   \n",
       "206           0.07232        0.017560             0.019520         0.1934   \n",
       "102           0.04038        0.023830             0.017700         0.1739   \n",
       "15            0.15950        0.163900             0.073640         0.2303   \n",
       "51            0.06059        0.018570             0.017230         0.1353   \n",
       "40            0.06031        0.031100             0.020310         0.1784   \n",
       "35            0.13360        0.134800             0.060180         0.1896   \n",
       "142           0.09486        0.020310             0.018610         0.1645   \n",
       "154           0.08498        0.092930             0.034830         0.1822   \n",
       "193           0.13530        0.108500             0.045620         0.1943   \n",
       "314           0.05847        0.000000             0.000000         0.2163   \n",
       "\n",
       "     mean fractal dimension  ...  fractal dimension error  worst radius  \\\n",
       "107                 0.06066  ...                 0.001356        13.290   \n",
       "74                  0.05914  ...                 0.002304        14.110   \n",
       "301                 0.06249  ...                 0.004651        13.460   \n",
       "37                  0.05863  ...                 0.001777        13.300   \n",
       "27                  0.05699  ...                 0.004217        21.310   \n",
       "163                 0.06761  ...                 0.005348        13.580   \n",
       "245                 0.06440  ...                 0.003560        11.480   \n",
       "119                 0.05025  ...                 0.001902        20.580   \n",
       "181                 0.07398  ...                 0.005295        26.680   \n",
       "20                  0.06811  ...                 0.002425        14.500   \n",
       "213                 0.05866  ...                 0.012560        18.070   \n",
       "146                 0.07371  ...                 0.004635        13.740   \n",
       "328                 0.06277  ...                 0.002789        19.280   \n",
       "131                 0.05796  ...                 0.002461        19.260   \n",
       "209                 0.05526  ...                 0.001656        17.380   \n",
       "166                 0.06400  ...                 0.002120        11.600   \n",
       "187                 0.06095  ...                 0.001671        13.010   \n",
       "345                 0.07005  ...                 0.006758        10.880   \n",
       "63                  0.06963  ...                 0.005822        10.010   \n",
       "375                 0.06572  ...                 0.003696        16.970   \n",
       "323                 0.06670  ...                 0.003345        25.300   \n",
       "176                 0.08116  ...                 0.017920        11.260   \n",
       "54                  0.05684  ...                 0.001629        18.100   \n",
       "53                  0.06310  ...                 0.005126        20.600   \n",
       "106                 0.06520  ...                 0.003840        13.140   \n",
       "280                 0.06220  ...                 0.003446        23.720   \n",
       "315                 0.05673  ...                 0.001344        13.340   \n",
       "107                 0.06066  ...                 0.001356        13.290   \n",
       "199                 0.06466  ...                 0.001976        18.330   \n",
       "86                  0.05636  ...                 0.003249        16.210   \n",
       "..                      ...  ...                      ...           ...   \n",
       "316                 0.05649  ...                 0.000950        12.850   \n",
       "55                  0.05907  ...                 0.002386        12.840   \n",
       "260                 0.05572  ...                 0.001892        24.330   \n",
       "71                  0.08980  ...                 0.021930         9.733   \n",
       "191                 0.06287  ...                 0.005875        13.750   \n",
       "66                  0.06899  ...                 0.004237        10.410   \n",
       "23                  0.05278  ...                 0.001987        29.170   \n",
       "160                 0.06453  ...                 0.005061        13.320   \n",
       "10                  0.05697  ...                 0.003042        19.190   \n",
       "123                 0.06402  ...                 0.002808        15.700   \n",
       "173                 0.06669  ...                 0.004785        11.350   \n",
       "285                 0.05855  ...                 0.002015        13.500   \n",
       "83                  0.07224  ...                 0.010390        20.330   \n",
       "182                 0.05549  ...                 0.002430        20.110   \n",
       "184                 0.06317  ...                 0.002575        17.800   \n",
       "187                 0.06095  ...                 0.001671        13.010   \n",
       "224                 0.05674  ...                 0.002496        15.140   \n",
       "277                 0.04996  ...                 0.001676        19.960   \n",
       "338                 0.06331  ...                 0.002778        11.160   \n",
       "303                 0.06600  ...                 0.003317        11.060   \n",
       "206                 0.06285  ...                 0.002472        10.420   \n",
       "102                 0.05677  ...                 0.001532        13.340   \n",
       "15                  0.07077  ...                 0.005466        17.460   \n",
       "51                  0.05953  ...                 0.002551        14.670   \n",
       "40                  0.05587  ...                 0.001286        15.930   \n",
       "35                  0.05656  ...                 0.002665        20.010   \n",
       "142                 0.06562  ...                 0.003526        12.780   \n",
       "154                 0.06207  ...                 0.003479        14.770   \n",
       "193                 0.06937  ...                 0.005672        15.650   \n",
       "314                 0.07359  ...                 0.006820         8.952   \n",
       "\n",
       "     worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "107          27.49            85.56       544.1           0.11840   \n",
       "74           23.21            89.71       611.1           0.11760   \n",
       "301          23.07            88.13       551.3           0.10500   \n",
       "37           22.81            84.46       545.9           0.09701   \n",
       "27           27.26           139.90      1403.0           0.13380   \n",
       "163          28.68            87.36       553.0           0.14520   \n",
       "245          29.46            73.68       402.8           0.15150   \n",
       "119          27.83           129.20      1261.0           0.10720   \n",
       "181          33.48           176.50      2089.0           0.14910   \n",
       "20           20.49            96.09       630.5           0.13120   \n",
       "213          28.07           120.40      1021.0           0.12430   \n",
       "146          26.38            91.93       591.7           0.13850   \n",
       "328          30.38           129.80      1121.0           0.15900   \n",
       "131          26.00           124.90      1156.0           0.15460   \n",
       "209          15.92           113.70       932.7           0.12220   \n",
       "166          12.02            73.66       414.0           0.14360   \n",
       "187          21.39            84.42       521.5           0.13230   \n",
       "345          19.48            70.89       357.1           0.13600   \n",
       "63           19.23            65.59       310.1           0.09836   \n",
       "375          19.14           113.10       861.5           0.12350   \n",
       "323          31.86           171.10      1938.0           0.15920   \n",
       "176          24.39            73.07       390.2           0.13010   \n",
       "54           31.69           117.70      1030.0           0.13890   \n",
       "53           24.13           135.10      1321.0           0.12800   \n",
       "106          29.26            85.51       521.7           0.16880   \n",
       "280          35.90           159.80      1724.0           0.17820   \n",
       "315          19.71            84.48       544.2           0.11040   \n",
       "107          27.49            85.56       544.1           0.11840   \n",
       "199          30.12           117.90      1044.0           0.15520   \n",
       "86           29.25           108.40       808.9           0.13060   \n",
       "..             ...              ...         ...               ...   \n",
       "316          16.47            81.60       513.1           0.10010   \n",
       "55           22.47            81.81       506.2           0.12490   \n",
       "260          39.16           162.30      1844.0           0.15220   \n",
       "71           15.67            62.56       284.4           0.12070   \n",
       "191          23.50            89.04       579.5           0.09388   \n",
       "66           31.56            67.03       330.7           0.15480   \n",
       "23           35.59           188.00      2615.0           0.14010   \n",
       "160          26.21            88.91       543.9           0.13580   \n",
       "10           33.88           123.80      1150.0           0.11810   \n",
       "123          15.98           102.80       745.5           0.13130   \n",
       "173          16.82            72.01       396.5           0.12160   \n",
       "285          23.08            85.56       564.1           0.10380   \n",
       "83           32.72           141.30      1298.0           0.13920   \n",
       "182          32.82           129.30      1269.0           0.14140   \n",
       "184          28.03           113.80       973.1           0.13010   \n",
       "187          21.39            84.42       521.5           0.13230   \n",
       "224          23.60            98.84       708.8           0.12760   \n",
       "277          24.30           129.00      1236.0           0.12430   \n",
       "338          26.84            71.98       384.0           0.14020   \n",
       "303          24.54            70.76       375.4           0.14130   \n",
       "206          23.22            67.08       331.6           0.14150   \n",
       "102          32.84            84.58       547.8           0.11230   \n",
       "15           37.13           124.10       943.2           0.16780   \n",
       "51           23.19            96.08       656.7           0.10890   \n",
       "40           30.25           102.50       787.9           0.10940   \n",
       "35           29.02           133.50      1229.0           0.15630   \n",
       "142          26.76            82.66       503.0           0.14130   \n",
       "154          20.50            97.67       677.3           0.14780   \n",
       "193          39.34           101.70       768.9           0.17850   \n",
       "314          22.44            56.65       240.1           0.13470   \n",
       "\n",
       "     worst compactness  worst concavity  worst concave points  worst symmetry  \n",
       "107            0.19630         0.193700              0.084420          0.2983  \n",
       "74             0.18430         0.170300              0.086600          0.2618  \n",
       "301            0.21580         0.190400              0.076250          0.2685  \n",
       "37             0.04619         0.048330              0.050130          0.1987  \n",
       "27             0.21170         0.344600              0.149000          0.2341  \n",
       "163            0.23380         0.168800              0.081940          0.2268  \n",
       "245            0.10260         0.118100              0.067360          0.2883  \n",
       "119            0.12020         0.224900              0.118500          0.4882  \n",
       "181            0.75840         0.678000              0.290300          0.4098  \n",
       "20             0.27760         0.189000              0.072830          0.3184  \n",
       "213            0.17930         0.280300              0.109900          0.1603  \n",
       "146            0.40920         0.450400              0.186500          0.5774  \n",
       "328            0.29470         0.359700              0.158300          0.3103  \n",
       "131            0.23940         0.379100              0.151400          0.2837  \n",
       "209            0.21860         0.296200              0.103500          0.2320  \n",
       "166            0.12570         0.104700              0.046030          0.2090  \n",
       "187            0.10400         0.152100              0.109900          0.2572  \n",
       "345            0.16360         0.071620              0.040740          0.2434  \n",
       "63             0.16780         0.139700              0.050870          0.3282  \n",
       "375            0.25500         0.211400              0.125100          0.3153  \n",
       "323            0.44920         0.534400              0.268500          0.5558  \n",
       "176            0.29500         0.348600              0.099100          0.2614  \n",
       "54             0.20570         0.271200              0.153000          0.2675  \n",
       "53             0.22970         0.262300              0.132500          0.3021  \n",
       "106            0.26600         0.287300              0.121800          0.2806  \n",
       "280            0.38410         0.575400              0.187200          0.3258  \n",
       "315            0.04953         0.019380              0.027840          0.1917  \n",
       "107            0.19630         0.193700              0.084420          0.2983  \n",
       "199            0.40560         0.496700              0.183800          0.4753  \n",
       "86             0.19760         0.334900              0.122500          0.3020  \n",
       "..                 ...              ...                   ...             ...  \n",
       "316            0.05332         0.041160              0.018520          0.2293  \n",
       "55             0.08720         0.090760              0.063160          0.3306  \n",
       "260            0.29450         0.378800              0.169700          0.3151  \n",
       "71             0.24360         0.143400              0.047860          0.2254  \n",
       "191            0.08978         0.051860              0.047730          0.2179  \n",
       "66             0.16640         0.094120              0.065170          0.2878  \n",
       "23             0.26000         0.315500              0.200900          0.2822  \n",
       "160            0.18920         0.195600              0.079090          0.3168  \n",
       "10             0.15510         0.145900              0.099750          0.2948  \n",
       "123            0.17880         0.256000              0.122100          0.2889  \n",
       "173            0.08240         0.039380              0.043060          0.1902  \n",
       "285            0.06624         0.005579              0.008772          0.2505  \n",
       "83             0.28170         0.243200              0.184100          0.2311  \n",
       "182            0.35470         0.290200              0.154100          0.3437  \n",
       "184            0.32990         0.363000              0.122600          0.3175  \n",
       "187            0.10400         0.152100              0.109900          0.2572  \n",
       "224            0.13110         0.178600              0.096780          0.2506  \n",
       "277            0.11600         0.221000              0.129400          0.2567  \n",
       "338            0.14020         0.105500              0.064990          0.2894  \n",
       "303            0.10440         0.084230              0.065280          0.2213  \n",
       "206            0.12470         0.062130              0.055880          0.2989  \n",
       "102            0.08862         0.114500              0.074310          0.2694  \n",
       "15             0.65770         0.702600              0.171200          0.4218  \n",
       "51             0.15820         0.105000              0.085860          0.2346  \n",
       "40             0.20430         0.208500              0.111200          0.2994  \n",
       "35             0.38350         0.540900              0.181300          0.4863  \n",
       "142            0.17920         0.077080              0.064020          0.2584  \n",
       "154            0.22560         0.300900              0.097220          0.3849  \n",
       "193            0.47060         0.442500              0.145900          0.3215  \n",
       "314            0.07767         0.000000              0.000000          0.3142  \n",
       "\n",
       "[398 rows x 29 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = y_train.iloc[bagging.estimators_samples_[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = scaler.fit_transform(X_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(\n",
    "    Xs, ys, test_size=0.3, stratify=ys, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_s = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT CV training score:\t 0.6372077922077921\n",
      "DT test score:\t 0.6916666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"DT CV training score:\\t\", \n",
    "      cross_val_score(dt_s, Xs_train, ys_train, cv=5,\n",
    "                    n_jobs=1).mean())\n",
    "dt_s.fit(Xs_train, ys_train)\n",
    "print(\"DT test score:\\t\", dt_s.score(Xs_test, ys_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Bonus: Take each of the decision trees from the ensemble above and obtain its predictions for the target variable in the test set. Use majority voting to obtain the ensemble prediction for the target label. Compare with the bagging classifier score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
