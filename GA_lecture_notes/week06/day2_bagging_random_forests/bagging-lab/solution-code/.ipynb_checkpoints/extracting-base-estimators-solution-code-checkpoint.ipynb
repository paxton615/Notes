{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Extracting Base Estimators from Bagged Models \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will have to make use of the attributes available with sklearn's [BaggingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html). In particular\n",
    "you will need to investigate what you can do with \n",
    "- `.base_estimator_`\n",
    "- `.estimators_`\n",
    "- `.estimators_samples_`\n",
    "- `.estimators_features_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Load-the-breast-cancer-data.\" data-toc-modified-id=\"1.-Load-the-breast-cancer-data.-1\">1. Load the breast cancer data.</a></span></li><li><span><a href=\"#2.-Load-required-sklearn-packages.\" data-toc-modified-id=\"2.-Load-required-sklearn-packages.-2\">2. Load required sklearn packages.</a></span></li><li><span><a href=\"#3.-Make-a-train-test-split.\" data-toc-modified-id=\"3.-Make-a-train-test-split.-3\">3. Make a train-test split.</a></span></li><li><span><a href=\"#4.-Create-and-fit-a-BaggingClassifier-with-a-DecisionTreeClassifier-base-estimator.\" data-toc-modified-id=\"4.-Create-and-fit-a-BaggingClassifier-with-a-DecisionTreeClassifier-base-estimator.-4\">4. Create and fit a <code>BaggingClassifier</code> with a <code>DecisionTreeClassifier</code> base estimator.</a></span></li><li><span><a href=\"#5.-Pull-out-the-base-estimator-from-the-ensemble-model.\" data-toc-modified-id=\"5.-Pull-out-the-base-estimator-from-the-ensemble-model.-5\">5. Pull out the base estimator from the ensemble model.</a></span></li><li><span><a href=\"#6.-Pull-out-all-the-base-estimators.\" data-toc-modified-id=\"6.-Pull-out-all-the-base-estimators.-6\">6. Pull out <em>all</em> the base estimators.</a></span></li><li><span><a href=\"#7.-Get-the-features-used-in-each-of-the-bagged-base-estimators.\" data-toc-modified-id=\"7.-Get-the-features-used-in-each-of-the-bagged-base-estimators.-7\">7. Get the features used in each of the bagged base estimators.</a></span></li><li><span><a href=\"#8.-Create-a-list-of-the-features-used-in-the-first-base-estimator.\" data-toc-modified-id=\"8.-Create-a-list-of-the-features-used-in-the-first-base-estimator.-8\">8. Create a list of the features used in the first base estimator.</a></span></li><li><span><a href=\"#9.-Get-out-the-samples-used-in-our-first-base-estimator.\" data-toc-modified-id=\"9.-Get-out-the-samples-used-in-our-first-base-estimator.-9\">9. Get out the samples used in our first base estimator.</a></span></li><li><span><a href=\"#10.-Get-out-the-target-subsample-for-the-estimator.\" data-toc-modified-id=\"10.-Get-out-the-target-subsample-for-the-estimator.-10\">10. Get out the target subsample for the estimator.</a></span></li><li><span><a href=\"#11.-Fit-a-decision-tree-equivalent-to-our-first-base-estimator.\" data-toc-modified-id=\"11.-Fit-a-decision-tree-equivalent-to-our-first-base-estimator.-11\">11. Fit a decision tree equivalent to our first base estimator.</a></span></li><li><span><a href=\"#12.-Bonus:-Take-each-of-the-decision-trees-from-the-ensemble-above-and-obtain-its-predictions-for-the-target-variable-in-the-test-set.-Use-majority-voting-to-obtain-the-ensemble-prediction-for-the-target-label.-Compare-with-the-bagging-classifier-score.\" data-toc-modified-id=\"12.-Bonus:-Take-each-of-the-decision-trees-from-the-ensemble-above-and-obtain-its-predictions-for-the-target-variable-in-the-test-set.-Use-majority-voting-to-obtain-the-ensemble-prediction-for-the-target-label.-Compare-with-the-bagging-classifier-score.-12\">12. Bonus: Take each of the decision trees from the ensemble above and obtain its predictions for the target variable in the test set. Use majority voting to obtain the ensemble prediction for the target label. Compare with the bagging classifier score.</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the breast cancer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Converting data into a dataframe structure\n",
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "# Setting up our Y value as well\n",
    "y = pd.Series(data['target'])\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load required sklearn packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create and fit a `BaggingClassifier` with a `DecisionTreeClassifier` base estimator.\n",
    "\n",
    "- Fit on the training data.\n",
    "- Report the score on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "         max_samples=0.5, n_estimators=50, n_jobs=None, oob_score=True,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our classifier and our bag\n",
    "DT = DecisionTreeClassifier()\n",
    "BC = BaggingClassifier(base_estimator=DT,\n",
    "                       n_estimators=50,\n",
    "                       max_features=0.5,\n",
    "                       max_samples=0.5,\n",
    "                       oob_score=True)\n",
    "\n",
    "# Fitting the Bag\n",
    "BC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = BC.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906103286384976"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BC.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9507042253521126"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BC.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pull out the base estimator from the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting our bag's base model\n",
    "# We can only have one base model so our estimator models cannot have varying parameters\n",
    "# The Random_state is a reference seed.\n",
    "BC.base_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pull out *all* the base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1028862084, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=870353631, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=788373214, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1419052930, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=873768326, splitter='best')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the rest of our bag models.\n",
    "BC.estimators_[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Get the features used in each of the bagged base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([19,  0, 14,  6, 26, 16,  9, 15, 25, 20, 21,  5,  3, 24,  1]),\n",
       " array([ 7, 26, 21, 17, 18, 23,  6,  8, 22, 12, 28,  0, 13, 27, 15]),\n",
       " array([18, 16, 26, 10,  6, 14,  0, 23, 29,  4,  7, 12, 24, 28, 19]),\n",
       " array([15, 22, 12, 26,  2, 19, 28, 25,  0,  8, 21, 23, 27, 11,  3]),\n",
       " array([15, 24, 10,  7,  1, 28, 12, 16, 18,  5, 17, 19, 13,  9, 23])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the features in each of our bagged models,\n",
    "# that is their index values of the list of feature names\n",
    "BC.estimators_features_[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create a list of the features used in the first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False,\n",
       "            random_state=1028862084, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the parameters for the first decision tree in our bag?\n",
    "BC.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  0, 14,  6, 26, 16,  9, 15, 25, 20, 21,  5,  3, 24,  1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the features used in the first model\n",
    "BC.estimators_features_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373    0\n",
       "289    1\n",
       "208    1\n",
       "504    1\n",
       "499    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head().loc[373]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fractal dimension error',\n",
       " 'mean radius',\n",
       " 'smoothness error',\n",
       " 'mean concavity',\n",
       " 'worst concavity',\n",
       " 'concavity error',\n",
       " 'mean fractal dimension',\n",
       " 'compactness error',\n",
       " 'worst compactness',\n",
       " 'worst radius',\n",
       " 'worst texture',\n",
       " 'mean compactness',\n",
       " 'mean area',\n",
       " 'worst smoothness',\n",
       " 'mean texture']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list of the selected features\n",
    "\n",
    "sub_features = [data['feature_names'][feature]\n",
    "    for feature in BC.estimators_features_[0]]\n",
    "sub_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Get out the samples used in our first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the samples used in the first model?\n",
    "samples = BC.estimators_samples_[0]\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[178, 153, 167, 170, 176, 164, 174, 171, 173, 166]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of samples included in each ensemble member (remember max_samples)\n",
    "[np.unique(BC.estimators_samples_[i]).shape[0] for i in range(len(BC.estimators_))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the True Samples from our DT to sub down to X_train\n",
    "X_train_0 = X_train.loc[X_train.index[samples], sub_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>mean texture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.003411</td>\n",
       "      <td>11.46</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.03344</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.02221</td>\n",
       "      <td>0.06243</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>12.68</td>\n",
       "      <td>21.61</td>\n",
       "      <td>0.07694</td>\n",
       "      <td>403.1</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>18.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.003442</td>\n",
       "      <td>11.28</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.02187</td>\n",
       "      <td>0.06072</td>\n",
       "      <td>0.03498</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>13.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.005667</td>\n",
       "      <td>11.84</td>\n",
       "      <td>0.005551</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.69560</td>\n",
       "      <td>0.04205</td>\n",
       "      <td>0.07799</td>\n",
       "      <td>0.03414</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>16.82</td>\n",
       "      <td>28.12</td>\n",
       "      <td>0.15160</td>\n",
       "      <td>440.6</td>\n",
       "      <td>0.1637</td>\n",
       "      <td>18.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.001621</td>\n",
       "      <td>16.14</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.23100</td>\n",
       "      <td>0.01831</td>\n",
       "      <td>0.05875</td>\n",
       "      <td>0.01246</td>\n",
       "      <td>0.1722</td>\n",
       "      <td>17.71</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.08501</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>14.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.005002</td>\n",
       "      <td>20.94</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.27120</td>\n",
       "      <td>0.69910</td>\n",
       "      <td>0.09518</td>\n",
       "      <td>0.05898</td>\n",
       "      <td>0.03908</td>\n",
       "      <td>0.3172</td>\n",
       "      <td>25.58</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0.16060</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>23.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fractal dimension error  mean radius  smoothness error  mean concavity  \\\n",
       "304                 0.003411        11.46          0.006652         0.03344   \n",
       "139                 0.003442        11.28          0.011270         0.04635   \n",
       "31                  0.005667        11.84          0.005551         0.12180   \n",
       "406                 0.001621        16.14          0.003958         0.05500   \n",
       "250                 0.005002        20.94          0.005283         0.27120   \n",
       "\n",
       "     worst concavity  concavity error  mean fractal dimension  \\\n",
       "304          0.12260          0.02221                 0.06243   \n",
       "139          0.08669          0.02187                 0.06072   \n",
       "31           0.69560          0.04205                 0.07799   \n",
       "406          0.23100          0.01831                 0.05875   \n",
       "250          0.69910          0.09518                 0.05898   \n",
       "\n",
       "     compactness error  worst compactness  worst radius  worst texture  \\\n",
       "304            0.02652             0.1789         12.68          21.61   \n",
       "139            0.03498             0.1822         11.92          15.77   \n",
       "31             0.03414             0.5775         16.82          28.12   \n",
       "406            0.01246             0.1722         17.71          19.58   \n",
       "250            0.03908             0.3172         25.58          27.00   \n",
       "\n",
       "     mean compactness  mean area  worst smoothness  mean texture  \n",
       "304           0.07694      403.1            0.1144         18.16  \n",
       "139           0.11360      384.8            0.1367         13.39  \n",
       "31            0.15160      440.6            0.1637         18.70  \n",
       "406           0.08501      800.0            0.1206         14.86  \n",
       "250           0.16060     1364.0            0.1211         23.56  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Get out the target subsample for the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the y_train sub sample used.\n",
    "#target = pd.DataFrame(y_train)\n",
    "y_train_0 = y_train[y_train.index[samples]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Fit a decision tree equivalent to our first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916083916083916"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the Decision Tree in our First base model of our bagged classifier.\n",
    "DTC_0 = BC.estimators_[0]\n",
    "\n",
    "# Fitting the model\n",
    "DTC_0.fit(X_train_0, y_train_0)\n",
    "\n",
    "# accuracy on the test set\n",
    "predictions_DTC_0 = DTC_0.predict(X_test[sub_features])\n",
    "accuracy_score(y_test, predictions_DTC_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Bonus: Take each of the decision trees from the ensemble above and obtain its predictions for the target variable in the test set. Use majority voting to obtain the ensemble prediction for the target label. Compare with the bagging classifier score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916083916083916\n",
      "0.8951048951048951\n",
      "0.916083916083916\n",
      "0.9230769230769231\n",
      "0.8881118881118881\n",
      "0.8811188811188811\n",
      "0.9300699300699301\n",
      "0.9440559440559441\n",
      "0.9440559440559441\n",
      "0.916083916083916\n",
      "0.9370629370629371\n",
      "0.951048951048951\n",
      "0.9090909090909091\n",
      "0.9370629370629371\n",
      "0.9370629370629371\n",
      "0.9230769230769231\n",
      "0.8741258741258742\n",
      "0.8811188811188811\n",
      "0.951048951048951\n",
      "0.9020979020979021\n",
      "0.9090909090909091\n",
      "0.9300699300699301\n",
      "0.965034965034965\n",
      "0.9440559440559441\n",
      "0.9440559440559441\n",
      "0.8881118881118881\n",
      "0.965034965034965\n",
      "0.965034965034965\n",
      "0.8881118881118881\n",
      "0.9370629370629371\n",
      "0.9370629370629371\n",
      "0.9370629370629371\n",
      "0.9230769230769231\n",
      "0.951048951048951\n",
      "0.9300699300699301\n",
      "0.9440559440559441\n",
      "0.9090909090909091\n",
      "0.9230769230769231\n",
      "0.916083916083916\n",
      "0.9370629370629371\n",
      "0.9440559440559441\n",
      "0.9440559440559441\n",
      "0.9230769230769231\n",
      "0.951048951048951\n",
      "0.9020979020979021\n",
      "0.9440559440559441\n",
      "0.9440559440559441\n",
      "0.8951048951048951\n",
      "0.8461538461538461\n",
      "0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "df_predictions = pd.DataFrame()\n",
    "df_probabilities = pd.DataFrame()\n",
    "\n",
    "for i, estimator in enumerate(BC.estimators_):\n",
    "    # Creating a list of the selected features.\n",
    "    sub_features = [data['feature_names'][feature]\n",
    "        for feature in BC.estimators_features_[i]]\n",
    "\n",
    "    # sub_features\n",
    "\n",
    "    # What are the samples used in the i-th model?\n",
    "    samples = BC.estimators_samples_[i]\n",
    "    data_current = X_train.loc[X_train.index[samples], sub_features]\n",
    "    target_current = y_train[y_train.index[samples]]\n",
    "\n",
    "    # Fitting the model\n",
    "    estimator.fit(data_current, target_current)\n",
    "\n",
    "    # accuracy on the test set\n",
    "    predictions_estimator = estimator.predict(X_test[sub_features])\n",
    "    probabilities_estimator = estimator.predict_proba(X_test[sub_features])\n",
    "    df_predictions['predictions_'+str(i)] = predictions_estimator\n",
    "    df_probabilities['probabilities_0_'+str(i)] = probabilities_estimator[:, 0]\n",
    "    df_probabilities['probabilities_1_'+str(i)] = probabilities_estimator[:, 1]\n",
    "    accuracy = accuracy_score(y_test, predictions_estimator)\n",
    "    accuracies.append(accuracy)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924895104895105"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = []\n",
    "ones = []\n",
    "for i in range(len(df_predictions)):\n",
    "    counts = df_predictions.iloc[i].value_counts()\n",
    "    try:\n",
    "        zeros.append(counts[0])\n",
    "    except:\n",
    "        zeros.append(0)\n",
    "    try:\n",
    "        ones.append(counts[1])\n",
    "    except:\n",
    "        ones.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions_0</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>predictions_2</th>\n",
       "      <th>predictions_3</th>\n",
       "      <th>predictions_4</th>\n",
       "      <th>predictions_5</th>\n",
       "      <th>predictions_6</th>\n",
       "      <th>predictions_7</th>\n",
       "      <th>predictions_8</th>\n",
       "      <th>predictions_9</th>\n",
       "      <th>...</th>\n",
       "      <th>predictions_43</th>\n",
       "      <th>predictions_44</th>\n",
       "      <th>predictions_45</th>\n",
       "      <th>predictions_46</th>\n",
       "      <th>predictions_47</th>\n",
       "      <th>predictions_48</th>\n",
       "      <th>predictions_49</th>\n",
       "      <th>zeros</th>\n",
       "      <th>ones</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions_0  predictions_1  predictions_2  predictions_3  predictions_4  \\\n",
       "0              0              0              0              0              0   \n",
       "1              1              1              1              1              1   \n",
       "2              1              1              0              1              0   \n",
       "3              1              1              1              1              1   \n",
       "4              1              1              1              1              1   \n",
       "\n",
       "   predictions_5  predictions_6  predictions_7  predictions_8  predictions_9  \\\n",
       "0              0              0              0              0              0   \n",
       "1              1              1              1              1              1   \n",
       "2              1              1              1              1              1   \n",
       "3              1              1              1              1              1   \n",
       "4              1              1              1              1              1   \n",
       "\n",
       "   ...  predictions_43  predictions_44  predictions_45  predictions_46  \\\n",
       "0  ...               0               0               0               0   \n",
       "1  ...               1               1               1               1   \n",
       "2  ...               1               1               1               0   \n",
       "3  ...               1               1               1               1   \n",
       "4  ...               1               1               1               1   \n",
       "\n",
       "   predictions_47  predictions_48  predictions_49  zeros  ones  prediction  \n",
       "0               0               0               0     50     0           0  \n",
       "1               1               1               1      0    50           1  \n",
       "2               1               1               1      9    41           1  \n",
       "3               1               1               1      0    50           1  \n",
       "4               1               1               1      0    50           1  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions['zeros'] = zeros\n",
    "df_predictions['ones'] = ones\n",
    "df_predictions['prediction'] = df_predictions[['zeros', 'ones']].apply(\n",
    "    lambda x: 1 if x[1] > x[0] else 0, axis=1)\n",
    "\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50,  0,  9,  1, 23,  3, 15, 49, 20,  5,  2, 39, 46,  6, 10, 48,  4,\n",
       "       44, 37, 40,  8, 14, 42, 21, 29, 36, 19, 45,  7])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.zeros.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, df_predictions.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check agreement with bagging score\n",
    "accuracy_score(y_test, df_predictions.prediction) - \\\n",
    "    accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
