{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Coding AdaBoost from Scratch\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we want to code the AdaBoost algorithm from scratch and verify our results by comparing to the sklearn implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, have a look at [Jaime Pastor](\n",
    "https://github.com/jaimeps/adaboost-implementation/blob/master/adaboost.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Lesson Guide<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Coding-AdaBoost-from-Scratch\" data-toc-modified-id=\"Coding-AdaBoost-from-Scratch-1\">Coding AdaBoost from Scratch</a></span><ul class=\"toc-item\"><li><span><a href=\"#AdaBoost-main-points\" data-toc-modified-id=\"AdaBoost-main-points-1.1\">AdaBoost main points</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Adaboost-algorithm\" data-toc-modified-id=\"The-Adaboost-algorithm-1.1.1\">The Adaboost algorithm</a></span></li><li><span><a href=\"#Write-a-scoring-function\" data-toc-modified-id=\"Write-a-scoring-function-1.1.2\">Write a scoring function</a></span></li><li><span><a href=\"#Write-a-model-prediction-function\" data-toc-modified-id=\"Write-a-model-prediction-function-1.1.3\">Write a model prediction function</a></span></li><li><span><a href=\"#Write-a-function-which-returns-training-and-test-scores\" data-toc-modified-id=\"Write-a-function-which-returns-training-and-test-scores-1.1.4\">Write a function which returns training and test scores</a></span></li><li><span><a href=\"#Write-an-indicator-function\" data-toc-modified-id=\"Write-an-indicator-function-1.1.5\">Write an indicator function</a></span></li><li><span><a href=\"#Calculate-the-error-rate\" data-toc-modified-id=\"Calculate-the-error-rate-1.1.6\">Calculate the error rate</a></span></li><li><span><a href=\"#Write-a-function-for-calculating-the-current-alpha-from-the-error-rate\" data-toc-modified-id=\"Write-a-function-for-calculating-the-current-alpha-from-the-error-rate-1.1.7\">Write a function for calculating the current alpha from the error rate</a></span></li><li><span><a href=\"#Write-a-function-for-updating-the-importance-weights\" data-toc-modified-id=\"Write-a-function-for-updating-the-importance-weights-1.1.8\">Write a function for updating the importance weights</a></span></li><li><span><a href=\"#Write-a-function-for-updating-the-predictions-at-each-iteration-step\" data-toc-modified-id=\"Write-a-function-for-updating-the-predictions-at-each-iteration-step-1.1.9\">Write a function for updating the predictions at each iteration step</a></span></li><li><span><a href=\"#Write-a-function-which-converts-[0,1]-labels-to-[-1,1]-labels\" data-toc-modified-id=\"Write-a-function-which-converts-[0,1]-labels-to-[-1,1]-labels-1.1.10\">Write a function which converts [0,1]-labels to [-1,1]-labels</a></span></li><li><span><a href=\"#Create-your-adaboost-model\" data-toc-modified-id=\"Create-your-adaboost-model-1.1.11\">Create your adaboost model</a></span></li><li><span><a href=\"#Fit-the-model\" data-toc-modified-id=\"Fit-the-model-1.1.12\">Fit the model</a></span></li><li><span><a href=\"#Check-your-model-on-these-datasets\" data-toc-modified-id=\"Check-your-model-on-these-datasets-1.1.13\">Check your model on these datasets</a></span></li><li><span><a href=\"#Compare-your-results-to-the-ones-obtained-with-sklearn.\" data-toc-modified-id=\"Compare-your-results-to-the-ones-obtained-with-sklearn.-1.1.14\">Compare your results to the ones obtained with sklearn.</a></span></li></ul></li><li><span><a href=\"#Bonus:-Construct-a-class-out-of-your-model-fitting-function\" data-toc-modified-id=\"Bonus:-Construct-a-class-out-of-your-model-fitting-function-1.2\">Bonus: Construct a class out of your model fitting function</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set(font_scale=1.5)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_hastie_10_2, make_moons\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost main points\n",
    "\n",
    "---\n",
    "\n",
    "Recall,\n",
    "\n",
    "$$ {\\rm AdaBoost}(X) = {\\rm sign}\\left(\\sum_{t=1}^T\\alpha_t h_t(X)\\right) $$\n",
    "\n",
    "where\n",
    "\n",
    "- ${\\rm AdaBoost}(X)$ are the classification predictions for $y$ using the predictor matrix $X$\n",
    "\n",
    "- $T$ is the set of \"weak learners\"\n",
    "\n",
    "- $\\alpha_t$ is the contribution weight for weak learner $t$\n",
    "\n",
    "- $h_t(X)$ is the prediction of weak learner $t$\n",
    "\n",
    "- $y$ is binary **with values -1 and 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Adaboost algorithm\n",
    "\n",
    "- initialize weights $w_0=1/N$ ($N$ is the number of observations)\n",
    "- for t=1:T do\n",
    "    - Fit a classifier $h_t(X)$ to the training set $X$ using weights $w$\n",
    "    - Compute the error rate \n",
    "$\\epsilon_t = \\frac{\\sum_{i=1}^N w_{i,t} {I}(y_i\\neq h_t(X_i))}{\\sum_{i=1}^N w_{i,t}} $\n",
    "    - Compute $ \\alpha_t = \\log \\left(\\frac{1-\\epsilon_t}{\\epsilon_t}\\right) \\text{where } \\epsilon_t < 1$\n",
    "    - Set $ w_{t+1,i} = w_{t,i} e^{\\alpha_t  {I}(y_i\\neq h_t(X_i))} $\n",
    "- Return $ {\\rm AdaBoost}(X) = {\\rm sign}\\left(\\sum_{t=1}^T\\alpha_t h_t(X)\\right) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a scoring function\n",
    "\n",
    "We will need a function which calculates any specific score given true and predicted labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def do_cross_val(model, X, y, cv=5):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, n_jobs=1,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "    # , scores.std()#, cross_val_score(model, X, y, cv=cv, n_jobs=1).mean()\n",
    "    return -scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y, pred, score=accuracy_score):\n",
    "    \"\"\"\n",
    "    arguments: target values and predicted values\n",
    "    returns: score\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a model prediction function\n",
    "\n",
    "Write a function which takes a model, training and test sets and sample weights. In the function body, fit the model, make prediction for training and test set and return them.\n",
    "\n",
    "Hint: Use `model.fit(X_train, y_train, sample_weight=sample_weight)` to take the weights into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictions(y_train, X_train, y_test, X_test, model, sample_weight=None):\n",
    "    \"\"\"\n",
    "    arguments: model, training and test sets, sample weights\n",
    "    body: fit the model and make predicitions\n",
    "    returns: training predictions and test predictions\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function which returns training and test scores\n",
    "\n",
    "This combines the previous two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_model(y_train, X_train, y_test, X_test, model):\n",
    "    \"\"\"\n",
    "    arguments: train and test sets for X, y and a model\n",
    "    fits the model on the training data and obtains train/test predictions\n",
    "    returns: train/test scores\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write an indicator function\n",
    "It should return 1 for disagreement between true and predicted labels and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_function(y, pred):\n",
    "    \"\"\"\n",
    "    arguments: target variable and predicted values\n",
    "    returns: 1 if disagreement, 0 else\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the error rate\n",
    "\n",
    "$$\\epsilon_t = \\frac{\\sum_{i=1}^N w_{i,t} {I}(y_i\\neq h_t(X_i))}{\\sum_{i=1}^N w_{i,t}}$$\n",
    "\n",
    "Make use of your indicator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error_rate(w, miss):\n",
    "    \"\"\"\n",
    "    arguments: weights and mask for misclassified data points (miss)\n",
    "    returns: error rate\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function for calculating the current alpha from the error rate\n",
    "\n",
    "$ \\alpha_t = \\log \\left(\\frac{1-\\epsilon_t}{\\epsilon_t}\\right) \\text{where } \\epsilon_t < 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alpha(error_rate):\n",
    "    \"\"\"\n",
    "    calculates the alpha value at current iteration step\n",
    "    argument: error rate\n",
    "    returns: alpha_m\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function for updating the importance weights\n",
    "\n",
    "$ w_{t+1,i} = w_{t,i} e^{\\alpha_t  {I}(y_i\\neq h_t(X_i))} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_importance_weights(w, miss, alpha_t):\n",
    "    \"\"\"\n",
    "    arguments: current weights, mask for misclassified observations, alpha_m\n",
    "    returns: w, the updated weight\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function for updating the predictions at each iteration step\n",
    "\n",
    "$\\sum_{t=1}^T\\alpha_t h_t(X)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_predictions(pred, pred_t, alpha_t):\n",
    "    \"\"\"\n",
    "    update the predictions with the ones of the current model\n",
    "    arguments: previous aggregated predictions (pred), \n",
    "               predictions at current iteration,\n",
    "               alpha_m\n",
    "    returns: updated predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function which converts [0,1]-labels to [-1,1]-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_converter(y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your adaboost model\n",
    "\n",
    "This function combines the helper functions from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_model(y_train, X_train, y_test, X_test, M, model):\n",
    "    \"\"\"\n",
    "    adaboost implementation\n",
    "    arguments: train/test X and y, number of iterations M, model\n",
    "    returns: model train/test scores\n",
    "    \"\"\"\n",
    "    # measure size of train/test sets\n",
    "    n_train, n_test = len(X_train), len(X_test)\n",
    "    # Initialize weights\n",
    "    w = np.ones(n_train) / n_train\n",
    "    # Initialize train/test predictions\n",
    "    pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "    # convert labels to 1/-1\n",
    "    ytilde_train = binary_converter(y_train)\n",
    "    ytilde_test = binary_converter(y_test)\n",
    "    \n",
    "    for i in range(M):\n",
    "        # Fit a classifier with the current weights\n",
    "        pred_train_i, pred_test_i = model_predictions(\n",
    "            y_train, X_train, y_test, X_test,\n",
    "            model, sample_weight=w)\n",
    "        \n",
    "        # convert predicted labels to 1/-1\n",
    "        pred_train_i = binary_converter(pred_train_i)\n",
    "        pred_test_i = binary_converter(pred_test_i)\n",
    "        # Indicator function\n",
    "        miss = indicator_function(pred_train_i, ytilde_train)\n",
    "        # Error\n",
    "        err_m = calculate_error_rate(w, miss)\n",
    "        # Alpha\n",
    "        alpha_m = calculate_alpha(err_m)\n",
    "        # update weights\n",
    "        w = update_importance_weights(w, miss, alpha_m)\n",
    "        # Add to prediction\n",
    "        pred_train = update_predictions(pred_train, pred_train_i, alpha_m)\n",
    "        pred_test = update_predictions(pred_test, pred_test_i, alpha_m)\n",
    "\n",
    "    # get the sign of train/test predictions\n",
    "    pred_train, pred_test = np.sign(pred_train), np.sign(pred_test)\n",
    "    \n",
    "    # Return train/test scores\n",
    "    return get_score(ytilde_train, pred_train), \\\n",
    "        get_score(ytilde_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model \n",
    "\n",
    "- Instantiate a classification model (decision tree)\n",
    "- Loop over a number of iteration steps\n",
    "- Obtain the training and test scores at each iteration step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your model on these datasets\n",
    "\n",
    "1.\n",
    "\n",
    "```python \n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "```  \n",
    "\n",
    "2. \n",
    "\n",
    "```python\n",
    "X, y = make_hastie_10_2(random_state=1)\n",
    "```\n",
    "\n",
    "3.\n",
    "```python\n",
    "X, y = make_moons(n_samples=100, noise=0.1, random_state=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare your results to the ones obtained with sklearn.\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "```\n",
    "\n",
    "Hint: It is essential that you set\n",
    "\n",
    "```python\n",
    "algorithm='SAMME'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Construct a class out of your model fitting function\n",
    "\n",
    "Think carefully how you would structure your class using the functions from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Lesson Guide",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
