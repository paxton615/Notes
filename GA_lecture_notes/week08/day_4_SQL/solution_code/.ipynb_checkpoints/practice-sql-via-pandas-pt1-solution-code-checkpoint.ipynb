{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Practice SQL with `pandas`, Pt. 1\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: `pandas` and SQL\n",
    "\n",
    "\n",
    "### The `pandas` Connector and Functions for SQL\n",
    "\n",
    "We can leverage SQL through `pandas`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pd.read_sql_table(table_name, con[, schema, ...])\n",
    "- Reads a SQL database table into a DataFrame.\n",
    "\n",
    "#### pd.read_sql_query(sql, con[, index_col, ...])\n",
    "- Reads a SQL query into a DataFrame.\n",
    "\n",
    "#### pd.read_sql(sql, con[, index_col, ...])\n",
    "- Reads a SQL query or database table into a DataFrame.\n",
    "- Adds a convenience wrapper around `read_sql_table()` and `read_sql_query()`.\n",
    "- Delegates to a specific function, depending on the provided input.\n",
    "\n",
    "#### DataFrame.to_sql(name, con[, flavor, ...])\n",
    "- Writes records stored in a DataFrame to a SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.  Create a SQL DB and tables using `pandas` DFs and `.csv`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, we will need to read our`.csv` files into Python before we can use it to convert them to a SQL-style DataFrame.\n",
    "\n",
    "**Now, let's connect to the SQLite database. If no database exists, our command will create one.**\n",
    "\n",
    "*Keep in mind that the directory your notebook opens is its base directory for all future SQL actions.*\n",
    "\n",
    "```python\n",
    "connection = sqlite3.connect('./datasets/sql/Cars.db.sqlite')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b45cba611247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/Cars.db.sqlite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcar_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/car-names.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "connection = sqlite3.connect('./datasets/Cars.db.sqlite')\n",
    "car_names = pd.read_csv('./datasets/car-names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking what our DataFrame looks like.\n",
    "car_names.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for nulls in our data.\n",
    "car_names.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the loaded `.csv` to a SQL file.  \n",
    "Because DataFrames are similar to SQL tables, you can now read and convert a `pandas` DataFrame named `car_names` into a SQL table in the newly created SQLite database above.\n",
    "\n",
    "```python\n",
    "car_names.to_sql(name = 'car_names', con = connection, if_exists = 'replace', index = False)\n",
    "```\n",
    "\n",
    "Important `.to_sql` arguments include:\n",
    "- `name`: The name of the table; useful if you have multiple tables in a SQL database.\n",
    "- `con`: The connection path to where the data should be placed.\n",
    "- `if_exists`: The condition to pass if the table already exists.\n",
    "\n",
    "If you check that directory now, you should see a `cars.db` SQL file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a DataFrame into a SQL database.\n",
    "car_names.to_sql(name = 'car_names', con = connection, if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** If you wanted a temporary SQL database, using the command below would allow you to access a database store in memory (RAM) as opposed to in storage.\n",
    "\n",
    "``` python\n",
    "conn = sqlite3.connect(':memory:')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a table in the `cars` database for car makers.\n",
    "\n",
    "The table should be called `car_makers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_makers_csv = './datasets/car-makers.csv'\n",
    "\n",
    "# Creating a table for order breakdowns.\n",
    "makers = pd.read_csv(car_makers_csv)\n",
    "\n",
    "makers.to_sql(name = 'car_makers', con = connection, if_exists = 'replace', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a table in the `cars` database for the car data.\n",
    "\n",
    "The table should be called `car_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data_csv = './datasets/cars-data.csv'\n",
    "\n",
    "# Creating a table for the sales targets.\n",
    "data = pd.read_csv(car_data_csv)\n",
    "\n",
    "data.to_sql(name = 'car_data', con = connection, if_exists = 'replace', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using a query string, read the entire `car_names` table from your SQL database into a DataFrame.\n",
    "\n",
    "Reading into a DataFrame with a query string can be accomplished using:\n",
    "```python\n",
    "# Use `read_sql` from the `pandas` library and set it equal to a DF object.\n",
    "cars = pd.read_sql(query_string, con = connection)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our SQL query:\n",
    "query = 'SELECT * FROM car_names'\n",
    "\n",
    "# Use `read_sql` from the `pandas` SQL library and set it equal to a DF object:\n",
    "results = pd.read_sql(query, con = connection)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tip:** If you type `Shift + Tab` in the function call, you can see that the `read_sql` function takes the arguments 'sql' and 'con.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side Note: Normalized vs. Denormalized Databases\n",
    "\n",
    "---\n",
    "\n",
    "There are several ways to organize data in a relational database. Two common definitions for data set ups are **normalized** and **denormalized**.\n",
    "\n",
    "- __Normalized__ structures include a single table per entity and use many foreign keys or link tables to connect entities together.\n",
    "\n",
    "- __Denormalized__ structures have fewer tables and may (for example) place all of the tweets and user information in one table.\n",
    "\n",
    "Each style has its own advantages and disadvantages. Denormalized tables duplicate a lot of information. For example, in a combined tweets/users table, we may store the address of each user. Now, instead of storing this once per user, we are storing it once per tweet!\n",
    "\n",
    "However, this makes the data easy to access if we ever need to find the tweet _and_ the user's location.\n",
    "\n",
    "Normalized tables save the storage space by separating the information. However, if we ever need to access two pieces of information at once — like in our example — we would need to join the corresponding tables, which can take more time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a Python function to query a database using `pandas` and return a DataFrame.\n",
    "\n",
    "The function should take two arguments:\n",
    "- The query string\n",
    "- The database connection object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case typing out `sql.read_sql()` is a little too much,\n",
    "# we'll create a function shortcut.\n",
    "\n",
    "CARS = sqlite3.connect('./datasets/Cars.db.sqlite')\n",
    "\n",
    "def Q(query, db=CARS):\n",
    "    return pd.read_sql(query, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Select the first five rows of the `car_names` table.\n",
    "\n",
    "> **Hint**: The LIMIT command in SQL can limit the number of rows returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q('SELECT * FROM car_names LIMIT 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Add the cars into the `car_names` table.\n",
    "\n",
    "The `.execute()` function will come in handy here, executing a SQL command string.\n",
    "```python\n",
    "connection.execute()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferrari = (None, 'Ferrari','The Ferrari')\n",
    "tesla = [None, 'Tesla', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARS.execute('INSERT INTO car_names VALUES (?, ?, ?)', ferrari)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARS.execute('INSERT INTO car_names VALUES (?, ?, ?)',tesla)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Query the `car_names` table for all columns where `'Model' = 'Tesla.'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q('SELECT * FROM car_names WHERE Model = \"Tesla\"')\n",
    "#Q('SELECT * FROM car_names WHERE Model = \\\"Tesla\\\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Select the first five rows of the `car_makers` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q('SELECT * FROM car_makers LIMIT 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Select the first five rows of the `car_data` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q('SELECT * FROM car_data ORDER BY MPG DESC LIMIT 5').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q('SELECT * FROM car_data').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sql join types](./images/sql-joins.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In our example, we can use Order ID as the matching feature to perform merges.\n",
    "\n",
    "Let's check out all of the ways we can merge these tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Practice INNER JOINs\n",
    "\n",
    "The most common type of JOIN is `SQL INNER JOIN` (SIMPLE JOIN). A `SQL INNER JOIN` returns all rows from multiple tables in which the JOIN condition is met. \n",
    "\n",
    "If we `INNER JOIN` on `Id`, it takes the intersection of the two tables, excluding the rows for which `CustomerID` is NULL in EITHER of the two tables.\n",
    "\n",
    "Essentially, only matching pairs of Order IDs from both data sets will be returned.\n",
    "\n",
    "**Select `Make`, `MPG`, `Horsepower`, and `Year`**.\n",
    "- You will need to `INNER JOIN` the `car_names` and `car_data` tables on the `Id` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join = Q(\n",
    "    'SELECT car_names.Make, car_data.MPG, car_data.Horsepower, car_data.Year '\n",
    "    'FROM car_names '\n",
    "    'INNER JOIN car_data '\n",
    "    'ON car_names.Id = car_data.Id ')\n",
    "inner_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR .. we can assign each table with an alias (here cn for car_names, cd for car_data)\n",
    "\n",
    "inner_join = Q(\n",
    "    'SELECT cn.Make, cd.MPG, cd.Horsepower, cd.Year '\n",
    "    'FROM car_names cn '\n",
    "    'INNER JOIN car_data cd '\n",
    "    'ON cn.Id = cd.Id ')\n",
    "inner_join.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Practice LEFT JOINs\n",
    "\n",
    "The `LEFT JOIN` keyword returns all rows from the left table (`table1`), along with matching rows in the right table (`table2`). When there is no match, the result is NULL on the right side.\n",
    "\n",
    "**Select `Make`, `MPG`, `Horsepower`, and `Year`**.\n",
    "- `SELECT FROM` the `car_names` table.\n",
    "- `LEFT JOIN` the `car_data` table by `Id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_join = Q(\n",
    "    'SELECT car_names.Make, car_data.MPG, car_data.Horsepower, car_data.Year '\n",
    "    'FROM car_names '\n",
    "    'LEFT JOIN car_data '\n",
    "    'ON car_names.Id =car_data.Id')\n",
    "left_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_join.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  RIGHT JOINs and FULL OUTER JOINs (Unsupported)\n",
    "\n",
    "> **Note:** We haven't included exercises for RIGHT and FULL OUTER JOINs, because they are not supported in this example.\n",
    "\n",
    "The `RIGHT JOIN` keyword would join all rows from the right table (`table2`) with the matching rows in the left table (`table1`). The result is NULL on the left side when there is no match.\n",
    "\n",
    "The `FULL OUTER JOIN` keyword returns all rows from the left table (`table1`) and the right table (`table2`). This JOIN combines results from both `LEFT` and `RIGHT` JOINs and all information from both tables into one. You can imagine that this can involve lots of repetitious information and/or NULL values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These resources are a bit long-winded but are good for explaining `pandas` functions from a SQL programmer's perspective:\n",
    "\n",
    "- [Pydata Video](https://www.youtube.com/watch?v=1uVWjdAbgBg)  \n",
    "- [Associated GitHub Repo](https://github.com/gjreda/pydata2014nyc/tree/master/data)\n",
    "- [`pandas` Merge, JOIN, and Concatenate](http://pandas.pydata.org/pandas-docs/stable/merging.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
