{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# SQL Together Lab: Learning SQL Syntax\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "*After this lesson, you will be able to:*\n",
    "- Sort results by column using `ORDER BY`.\n",
    "- Simplify your syntax using aliases (`AS`).\n",
    "- Match patterns using `LIKE`.\n",
    "- Select distinct items using `DISTINCT`.\n",
    "- Aggregate values using `GROUP BY`.\n",
    "- Filter on aggregations using `HAVING`.\n",
    "- Apply `IF/THEN` logic using `CASE`.\n",
    "- Use `EXTRACT` to get date parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Install `psycopg2`](#install-psycopg2)\n",
    "- [Connect to a Remote Database](#connect-to-remote)\n",
    "- [Some Notes on Syntax](#syntax-notes)\n",
    "- [ORDER BY](#order-by)\n",
    "- [Alias `AS`](#alias-as)\n",
    "- [LIKE](#like-operator)\n",
    "- [DISTINCT](#distinct)\n",
    "- [LIMIT](#limit)\n",
    "- [GROUP BY](#group-by)\n",
    "- [HAVING](#having)\n",
    "- [CASE Statements](#case)\n",
    "- [Working with Dates](#dates)\n",
    "- [Additional Exercises](#additional-exercises)\n",
    "- [Conclusion](#conclusion)\n",
    "- [Additional Resources](#additional-resources)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='install-psycopg2'></a>\n",
    "## Install `psycopg2`\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "`pip install -U psycopg2-binary`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='connect-to-remote'></a>\n",
    "## Connect to a Remote Database\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# DSN (data source name) format for database connections:  \n",
    "# [protocol / database  name]://[username]:[password]@[hostname / ip]:[port]/[database name here]\n",
    "\n",
    "conn_str ='postgresql://postgres:thewindisblowing@localhost:5432/northwind'\n",
    "conn = psycopg2.connect(conn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='order-by'></a>\n",
    "\n",
    "## `ORDER BY`\n",
    "\n",
    "---\n",
    "\n",
    "    The `ORDER BY` keyword is used to sort a result set by one or more columns. It sorts records in ascending order by default. To sort the records in descending order, you can use the `DESC` keyword.\n",
    "\n",
    "### SQL `ORDER BY` Syntax\n",
    "\n",
    "```*.sql\n",
    "SELECT column_name1, column_name2  \n",
    "FROM table_name  \n",
    "ORDER BY column_name1 ASC, column_name2 DESC;\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #1:\n",
    "\n",
    "Select the `ProductID`, `ProductName`, `SupplierID`, and `UnitPrice` for all `Products` with a `UnitPrice > 25`, ordered by `SupplierID` descending and then `UnitPrice` ascending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT product_id as pid, product_name, supplier_id, unit_price\n",
    "FROM products \n",
    "WHERE unit_price > 25 \n",
    "ORDER BY supplier_id DESC, unit_price ASC\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='alias-as'></a>\n",
    "## Alias `AS`\n",
    "\n",
    "---\n",
    "\n",
    "SQL aliases are used to give a database table — or a column in a table — a temporary name. Aliases are often created for two purposes:\n",
    "1. To make output column names more readable (substitute names). \n",
    "2. To make queries more concise (shorten query arguments).\n",
    "\n",
    "### SQL Alias Syntax for Columns\n",
    "\n",
    "```*.sql\n",
    "SELECT column_name AS alias_name  \n",
    "FROM table_name;\n",
    "```\n",
    "\n",
    "### SQL Alias Syntax for Tables\n",
    "\n",
    "```*.sql\n",
    "SELECT column_name(s)  \n",
    "FROM table_name AS alias_name;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #2\n",
    "\n",
    "Select `SupplierID` and `CompanyName` from the `Suppliers` table, aliasing these columns as `Supplier No.` and `Company Name`, respectively. Additionally, alias the `Suppliers` table as `S`. Order by `CompanyName` ascending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT supplier_id AS \"Supplier No.\", company_name AS \"Company Name\"  \n",
    "FROM suppliers AS S\n",
    "ORDER BY \"Company Name\" ASC\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Aliases can be useful when:**\n",
    "\n",
    "- More than one table is involved in a query.\n",
    "- Functions are used in the query.\n",
    "- Column names are long and/or not very readable.\n",
    "- Two or more columns are combined together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='like-operator'></a>\n",
    "## SQL's `LIKE` Operator\n",
    "\n",
    "---\n",
    "\n",
    "The `LIKE` operator is used in a `WHERE` clause to search for a specific pattern within a column.\n",
    "\n",
    "\n",
    "### SQL `LIKE` Syntax\n",
    "\n",
    "```*.sql\n",
    "\n",
    "SELECT column_name(s) \n",
    "FROM table_name  \n",
    "WHERE column_name LIKE pattern;\n",
    "\n",
    "```\n",
    "\n",
    "> **Tip**: The `\"%\"` sign is used to define wildcards (missing letters) both before and after the pattern. Also, notice that PostgreSQL is case sensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #3\n",
    "\n",
    "In descending order, select all products from the `Products` table with a `ProductName` that contains \"ch.\" Alias this column as `Ch Products`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT product_name AS \"Ch Products\"\n",
    "FROM products\n",
    "WHERE product_name LIKE '%ch%'\n",
    "ORDER BY product_name DESC\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #4\n",
    "\n",
    "In ascending order, select all products from the `Suppliers` table with a `City` that starts with \"S.\" Alias this column as `S Cities`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT P.product_name, S.city AS \"S Cities\"\n",
    "FROM suppliers S \n",
    "LEFT JOIN products P\n",
    "ON S.supplier_id = P.supplier_id\n",
    "WHERE city LIKE 'S%'\n",
    "ORDER BY product_name ASC\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='distinct'></a>\n",
    "## The `DISTINCT` operator\n",
    "\n",
    "---\n",
    "\n",
    "The `SELECT DISTINCT` statement is used to return _only_ distinct (unique) values. In a table, a column may contain many duplicate values; sometimes you'll only want to list the unique ones.\n",
    "\n",
    "### `SELECT DISTINCT` Syntax\n",
    "\n",
    "```*.sql\n",
    "\n",
    "SELECT DISTINCT column_name1, column_name2 \n",
    "FROM table_name;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #5\n",
    "\n",
    "`SELECT DISTINCT` `SupplierID`, `ProductName`, and `UnitPrice` from the `Products` table, ordering by `UnitPrice` ascending (i.e., the cheapest product for each supplier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT product_name\n",
    "FROM products as P\n",
    "ORDER BY P.product_name ASC\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='limit'></a>\n",
    "\n",
    "## The `LIMIT` operator\n",
    "\n",
    "---\n",
    "\n",
    "Sometimes, we may want to only retrieve a fixed number of records from a database. This is where the `LIMIT` operator comes in handy.\n",
    "\n",
    "\n",
    "### `LIMIT` Syntax\n",
    "\n",
    "```*.sql\n",
    "\n",
    "SELECT column_name1, column_name2  \n",
    "FROM table_name\n",
    "LIMIT number_of_records;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #6\n",
    "\n",
    "In ascending order, return the five highest-priced products that contain an \"a\" in the product name. Alias the column as `Top 5 A Products`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our sub query in the middle \n",
    "\n",
    "query = \"\"\"\n",
    "SELECT sub.\"Top 5 A Products\", sub.\"Unit Price\"\n",
    "FROM \n",
    "        (SELECT product_name AS \"Top 5 A Products\", unit_price AS \"Unit Price\"\n",
    "        FROM products\n",
    "        WHERE product_name LIKE '%a%'\n",
    "        ORDER BY unit_price DESC  \n",
    "        LIMIT 5) AS sub\n",
    "        \n",
    "ORDER BY \"Unit Price\" ASC\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#our sub-query first \n",
    "\n",
    "query = \"\"\"\n",
    "WITH sub as (SELECT product_name AS \"Top 5 A Products\", unit_price\n",
    "FROM products\n",
    "WHERE product_name LIKE '%a%'\n",
    "ORDER BY unit_price DESC  \n",
    "LIMIT 5)\n",
    "\n",
    "SELECT sub.\"Top 5 A Products\", sub.unit_price\n",
    "FROM sub \n",
    "ORDER BY unit_price ASC\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "_**Tip:** If you are finding this one a bit tricky to execute in one query, check out [SQL Subqueries](https://www.tutorialspoint.com/sql/sql-sub-queries.htm)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='group-by'></a>\n",
    "## `GROUP BY` Operator\n",
    "\n",
    "---\n",
    "\n",
    "A table may contain several records that have a common key. \n",
    "\n",
    "The `GROUP BY` statement is used in conjunction with aggregate functions to group a result set by one or more columns. For example, we may want to know the total number of items purchased in each order.\n",
    "\n",
    "### `GROUP BY` Syntax\n",
    "\n",
    "```*.sql\n",
    "SELECT column_name, aggregate_function(column_name)  \n",
    "FROM table_name  \n",
    "WHERE column_name operator value  \n",
    "GROUP BY column_name;\n",
    "```\n",
    "\n",
    "The aggregate functions you can use with `GROUP BY` are:\n",
    "- **`COUNT`**\n",
    "- **`MIN`**\n",
    "- **`MAX`**\n",
    "- **`SUM`**\n",
    "- **`AVG`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #7\n",
    "\n",
    "From the `Order_details` table, show the count of orders per `OrderID`, as well as the `SUM` of the revenue (`UnitPrice * Quantity`). Order by revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT  order_id, COUNT(order_id), SUM(unit_price*quantity) AS revenue\n",
    "FROM order_details\n",
    "GROUP BY order_id\n",
    "ORDER BY 3 DESC; \n",
    "\"\"\"\n",
    "\n",
    "#notice in the last line we reference the revenue column as the third column \n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='having'></a>\n",
    "## The `HAVING` operator\n",
    "\n",
    "---\n",
    "\n",
    "The `HAVING` clause was added to SQL because the `WHERE` keyword could not be used with aggregate functions. `HAVING` allows us to apply a filter while querying with them. For example, if we only wanted to show companies that had revenues greater than $10,000 (as calculated by an aggregate function).\n",
    "\n",
    "### `HAVING` Syntax\n",
    "\n",
    "``` *.sql\n",
    "\n",
    "SELECT column_name, aggregate_function(column_name)\n",
    "FROM table_name\n",
    "WHERE column_name operator value\n",
    "GROUP BY column_name\n",
    "HAVING aggregate_function(column_name) operator value;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #8\n",
    "\n",
    "Show the revenue of all orders with more than one item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT  order_id,COUNT(order_id) AS OrderCount, SUM(unit_price*quantity) AS revenue\n",
    "FROM order_details\n",
    "GROUP BY order_id\n",
    "HAVING COUNT(order_id) > 1\n",
    "ORDER BY revenue DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='case'></a>\n",
    "## `CASE` statements\n",
    "\n",
    "---\n",
    "\n",
    "The `CASE` statement is SQL’s way of applying `IF/THEN` logic. The `CASE` statement is followed by at least one pair of `WHEN` and `THEN` statements. It must end with an `END` statement. The `ELSE` statement is optional and provides a way to capture values not specified in the `WHEN/THEN` statements.\n",
    "\n",
    "### `CASE` Syntax\n",
    "\n",
    "Generic form: \n",
    "\n",
    "```*.sql\n",
    "SELECT \n",
    "    CASE WHEN column_name operator value THEN 'string value1'\n",
    "        WHEN column_name operator value THEN 'string value2'\n",
    "        ELSE 'string value3' END AS 'alias'         \n",
    "FROM table_name\n",
    "```\n",
    "\n",
    "Or, when testing values in one column only when we're testing for equality: \n",
    "\n",
    "\n",
    "```*.sql\n",
    "SELECT \n",
    "    CASE column_name WHEN value THEN 'string value1'\n",
    "        WHEN value THEN 'string value2'\n",
    "        ELSE 'string value3' END AS 'alias'         \n",
    "FROM table_name\n",
    "```\n",
    "\n",
    "\n",
    "### A Pseudocode Example\n",
    "\n",
    "```*.sql\n",
    "SELECT name\n",
    "    CASE WHEN age < 1 THEN 'infant'\n",
    "         WHEN age < 2 THEN 'toddler'\n",
    "         WHEN age < 5 THEN 'child'\n",
    "         ELSE 'old as dirt' END AS 'Persons Age'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #9\n",
    "\n",
    "Select `CompanyName`, `City`, and `Country` from the `Suppliers` table. Add a new column, `D_F`, which contains a value of \"domestic\" if the supplier is from the United States and \"foreign\" if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT company_name, city, country,\n",
    "    CASE country WHEN 'USA' THEN 'domestic' ELSE 'foreign' END AS domestic_foreign\n",
    "FROM suppliers\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='dates'></a>\n",
    "## Working With Dates\n",
    "\n",
    "---\n",
    "\n",
    "Take some time to look over the [PostgreSQL date documentation](https://www.postgresql.org/docs/8.1/static/functions-datetime.html).\n",
    "\n",
    "### Extracting Date Parts From a Date Object\n",
    "```*.sql\n",
    "SELECT my_date,\n",
    "       EXTRACT('year'   FROM my_date) AS year,\n",
    "       EXTRACT('month'  FROM my_date) AS month,\n",
    "       EXTRACT('day'    FROM my_date) AS day,\n",
    "       EXTRACT('hour'   FROM my_date) AS hour,\n",
    "       EXTRACT('minute' FROM my_date) AS minute,\n",
    "       EXTRACT('second' FROM my_date) AS second,\n",
    "       EXTRACT('decade' FROM my_date) AS decade,\n",
    "       EXTRACT('dow'    FROM my_date) AS day_of_week\n",
    "  FROM table_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #10\n",
    "\n",
    "Select `OrderDate` and `Freight` from the `Orders` table, along with three new columns for `Year`, `Month`, and `Day`. Make sure these are [_**cast**_ as integers, not floats](http://www.postgresqltutorial.com/postgresql-cast/).\n",
    "\n",
    "After extracting the dates as integers, pull out the `Year`, `Month`, and `SUM` of `Freight`, aliased as `FreightPerMonth`, grouping by the year and month, but only where the freight per month is greater than 5,000.\n",
    "\n",
    "Order this DataFrame by year and month descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT CAST(EXTRACT(year from order_date) AS INTEGER) AS year,\n",
    "    CAST(EXTRACT(month from order_date) AS INTEGER) AS month,\n",
    "    SUM(freight)\n",
    "FROM orders\n",
    "GROUP BY year, month\n",
    "HAVING SUM(freight) > 5000\n",
    "ORDER BY year DESC, month DESC;\n",
    "\"\"\"\n",
    "# Total freight per month\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #11\n",
    "\n",
    "From the `Orders` table, find the average number of days it took to ship a package per `ShipCountry`. Only include orders that have a ship date, and only show the top five results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT AVG(shipped_date - order_date) as avg_shipping_time, ship_country\n",
    "FROM orders\n",
    "WHERE shipped_date IS NOT NULL\n",
    "GROUP BY ship_country\n",
    "ORDER BY avg_shipping_time DESC\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #12\n",
    "\n",
    "In the `Orders` table, find the top five countries by average freight cost of products shipped in 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT ship_country, AVG(freight) AS AvgFreight\n",
    "FROM orders\n",
    "WHERE CAST(EXTRACT(year FROM shipped_date) AS Int) = 1998\n",
    "GROUP BY ship_country\n",
    "ORDER BY AvgFreight DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #13\n",
    "\n",
    "From the `Employees` table, find the two women who were hired the most recently. Exclude entries where gender is ambiguous.  \n",
    "_**Tip:** You may want to investigate the \"TitleOfCourtesy\" column._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT title_of_courtesy\n",
    "FROM employees\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH genders AS \n",
    "(SELECT title_of_courtesy, hire_date, \n",
    "    CASE WHEN title_of_courtesy IN ('Mrs.', 'Ms.') \n",
    "        THEN 'Female'\n",
    "        ELSE 'Male' \n",
    "        END AS Gender\n",
    "FROM employees)\n",
    "\n",
    "SELECT Gender, hire_date\n",
    "FROM genders\n",
    "WHERE genders.Gender = 'Female'\n",
    "ORDER BY hire_date DESC\n",
    "limit 2\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise #14\n",
    "\n",
    "Split products from the `Products` table into three price categories:\n",
    "- **Cheap**: Less than $10.\n",
    "- **Fair**: $10 to $50.\n",
    "- **Expensive**: Greater than $50.\n",
    "\n",
    "Return the count-per-product price categories, along with the `MIN`, `MAX`, and `AVG`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH product_cat AS\n",
    "  (SELECT unit_price,\n",
    "          CASE\n",
    "              WHEN unit_price > 50 THEN 'Expensive'\n",
    "              WHEN unit_price < 10 THEN 'Cheap'\n",
    "              ELSE 'Fair'\n",
    "          END AS Price_Indicator\n",
    "   FROM Products)\n",
    "   \n",
    "SELECT Price_Indicator,\n",
    "       COUNT(Price_Indicator),\n",
    "       MIN(unit_price),\n",
    "       MAX(unit_price),\n",
    "       AVG(unit_price)\n",
    "FROM product_cat\n",
    "GROUP BY Price_Indicator\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT Price_Indicator, COUNT(Price_Indicator), MIN(unit_price), MAX(unit_price), AVG(unit_price)\n",
    "FROM (SELECT unit_price,\n",
    "    CASE WHEN unit_price > 50 THEN 'Expensive'\n",
    "         WHEN unit_price < 10 THEN 'Cheap'\n",
    "         ELSE 'Fair' END AS Price_Indicator\n",
    "From Products) AS New_Table\n",
    "Group By New_Table.Price_Indicator\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it can help to test your sub-query first: \n",
    "\n",
    "query = \"\"\"\n",
    "SELECT unit_price,\n",
    "          CASE\n",
    "              WHEN unit_price > 50 THEN 'Expensive'\n",
    "              WHEN unit_price < 10 THEN 'Cheap'\n",
    "              ELSE 'Fair'\n",
    "          END AS Price_Indicator\n",
    "   FROM Products\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='conclusion'></a>\n",
    "## Conclusion\n",
    "\n",
    "---\n",
    "\n",
    "In this lesson, we've learned many new commands for making powerful SQL queries.\n",
    "\n",
    "In particular, we learned how to:\n",
    "\n",
    "- Sort results by column using `ORDER BY`.\n",
    "- Simplify our syntax using aliases.\n",
    "- Match patterns using `LIKE`.\n",
    "- Select distinct items using `DISTINCT`.\n",
    "- Aggregate values using `GROUP BY`.\n",
    "- Filter aggregations using `HAVING`.\n",
    "- Apply `IF/THEN` logic using `CASE`.\n",
    "- Use `EXTRACT` to get date parts.\n",
    "\n",
    "**Can you think of a few more business cases where these capabilities would be useful?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='additional-resources'></a>\n",
    "## Additional Resources\n",
    "\n",
    "---\n",
    "\n",
    "- [PostgreSQL Documenation](https://www.postgresql.org/docs/)\n",
    "- [Mode Analytics Tutorial](https://community.modeanalytics.com/sql/tutorial/introduction-to-sql/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
