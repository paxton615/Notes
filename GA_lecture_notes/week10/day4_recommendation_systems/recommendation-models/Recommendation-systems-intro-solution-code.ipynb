{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Recommendation Systems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Lesson Guide<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Users-and-items\" data-toc-modified-id=\"Users-and-items-1\">Users and items</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-2\">Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#MAE-and-MSE\" data-toc-modified-id=\"MAE-and-MSE-2.1\">MAE and MSE</a></span></li><li><span><a href=\"#Correlations\" data-toc-modified-id=\"Correlations-2.2\">Correlations</a></span></li><li><span><a href=\"#Precision@k-and-recall@k\" data-toc-modified-id=\"Precision@k-and-recall@k-2.3\">Precision@k and recall@k</a></span></li><li><span><a href=\"#Inter-user-diversity\" data-toc-modified-id=\"Inter-user-diversity-2.4\">Inter-user diversity</a></span></li><li><span><a href=\"#Intra-user-diversity\" data-toc-modified-id=\"Intra-user-diversity-2.5\">Intra-user diversity</a></span></li><li><span><a href=\"#Novelty\" data-toc-modified-id=\"Novelty-2.6\">Novelty</a></span></li><li><span><a href=\"#Coverage\" data-toc-modified-id=\"Coverage-2.7\">Coverage</a></span></li></ul></li><li><span><a href=\"#Baseline-prediction\" data-toc-modified-id=\"Baseline-prediction-3\">Baseline prediction</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-3.0.1\">Example</a></span></li></ul></li></ul></li><li><span><a href=\"#Similarity-based-methods\" data-toc-modified-id=\"Similarity-based-methods-4\">Similarity based methods</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-4.0.1\">Example</a></span></li><li><span><a href=\"#What-would-be-the-baseline-for-each-user-item-pair?\" data-toc-modified-id=\"What-would-be-the-baseline-for-each-user-item-pair?-4.0.2\">What would be the baseline for each user-item pair?</a></span></li><li><span><a href=\"#Measure-the-user-and-product-similarity-using-the-different-measures-from-the-above.\" data-toc-modified-id=\"Measure-the-user-and-product-similarity-using-the-different-measures-from-the-above.-4.0.3\">Measure the user and product similarity using the different measures from the above.</a></span></li><li><span><a href=\"#Determine-the-top-3-items-for-each-user.\" data-toc-modified-id=\"Determine-the-top-3-items-for-each-user.-4.0.4\">Determine the top-3 items for each user.</a></span></li><li><span><a href=\"#Determine-the-inter-user-diversity\" data-toc-modified-id=\"Determine-the-inter-user-diversity-4.0.5\">Determine the inter-user diversity</a></span></li><li><span><a href=\"#Determine-the-intra-user-diversity\" data-toc-modified-id=\"Determine-the-intra-user-diversity-4.0.6\">Determine the intra-user diversity</a></span></li><li><span><a href=\"#Determine-the-novelty\" data-toc-modified-id=\"Determine-the-novelty-4.0.7\">Determine the novelty</a></span></li><li><span><a href=\"#Determine-the-coverage\" data-toc-modified-id=\"Determine-the-coverage-4.0.8\">Determine the coverage</a></span></li></ul></li><li><span><a href=\"#KNN-with-means\" data-toc-modified-id=\"KNN-with-means-4.1\">KNN with means</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-4.1.1\">Example</a></span></li></ul></li><li><span><a href=\"#Slope-one-predictor\" data-toc-modified-id=\"Slope-one-predictor-4.2\">Slope-one predictor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-4.2.1\">Example</a></span></li></ul></li></ul></li><li><span><a href=\"#Content-based-filtering\" data-toc-modified-id=\"Content-based-filtering-5\">Content based filtering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Singular-Value-decomposition\" data-toc-modified-id=\"Singular-Value-decomposition-5.1\">Singular Value decomposition</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-TruncatedSVD-to-reduce-the-dimensionality-of-the-rating-matrix.\" data-toc-modified-id=\"Use-TruncatedSVD-to-reduce-the-dimensionality-of-the-rating-matrix.-5.1.1\">Use <code>TruncatedSVD</code> to reduce the dimensionality of the rating matrix.</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation systems are of high relevance for many companies providing online content. Everybody has frequently to interact with such systems. In this lesson we want to understand how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we try to recommend items to users, we face a few fundamental problems:\n",
    "\n",
    "1. Data Sparsity\n",
    "    - There are lots of products to recommend to many users. \n",
    "    - It is unlikely that a user will ever try out a large fraction of products.\n",
    "    - A few items are demanded by many users, but many only by a few.\n",
    "   \n",
    "- Cold Start\n",
    "    - We need to be able to give recommendations to users about which we only have scarse data (if at all).\n",
    "    \n",
    "- Accurate, but also diverse predictions\n",
    "    - We want to give useful recommendations in the sense that they match the user's preferences, but also that the recommendation contains some novelty for the user. \n",
    "\n",
    "- Evaluation\n",
    "    - Evaluation is difficult and might differ from algorithm to algorithm.\n",
    "\n",
    "- Scalability\n",
    "    - We need to be able to give recommendations on the spot even though there might be millions of users and items which we have to analyze carefully.\n",
    "\n",
    "- User interface\n",
    "    - Users want to know why they get particular recommendations.\n",
    "\n",
    "- Vulnerability to attacks\n",
    "    - We do not want our recommendation system to be abused for promoting or inhibiting particular items.\n",
    " \n",
    "- Temporal resolution\n",
    "    - Tastes and preferences do not remain the same over time. The algorithms that we will see neglect any kind of dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users and items\n",
    "\n",
    "In general we speak of users and items.\n",
    "\n",
    "> **Users:** indicate preferences for products through explicit/implicit ratings\n",
    "\n",
    "> **Items:** products which should be recommended and which have received ratings\n",
    "\n",
    "In most cases we are going to predict a certain rating for each possible pair of user and item. If the user already gave some rating we can compare it to our prediction:\n",
    "\n",
    "- True rating: $r_{ui}$\n",
    "- Predicted rating: $\\hat{r}_{ui}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE and MSE\n",
    "\n",
    "We can compare all existing ratings to our prediction for example using the root mean squared error (RMSE) or the mean absolute error (MAE):\n",
    "\n",
    "    \n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "{\\rm MAE} &=& \\frac{1}{|R|}\\sum_{(u,i)\\in R}|r_{ui}-{\\tilde r}_{ui}|\\\\\n",
    "{\\rm RMSE} &=& \\left(\\frac{1}{|R|}\\sum_{(u,i)\\in R}(r_{ui}-{\\tilde r}_{ui})^2\\right)^{1/2}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Here, $R$ stands for the set of all user-item pairs. $|\\cdot|$ indicates the cardinality of the set (here the number of user-item pairs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "Alternatively one can use correlations between true and predicted values for model evaluation, e.g.\n",
    "\n",
    "- the Pearson correlation\n",
    "- the Spearman rank correlation\n",
    "- Kendall's tau\n",
    "\n",
    "You can call these three for example with panda's `.corr()` function by setting the `method` argument.\n",
    "    \n",
    "The above scores are alright to obtain a model assessment if we have explicit ratings, but in the case of implicit ratings we might only be able to rank the items. In general, we would like to recommend the top-ranked items, but we have to evaluate if the top-ranked ones are really the ones relevant to the user, or if for some irrelevant items we predicted higher ratings.\n",
    "In that regard, we can use the usual classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision@k and recall@k\n",
    "\n",
    "Often users will not really care about all the rating predictions we are making, but instead they will have a major interest only in a few top-ranked items, let's say the $k$ top-ranked items. So it is appropriate to take only these $k$ ratings into account. We then ask how many of these $k$ items are relevant to the user. The relevance is in general difficult to measure, but we can for example ask how many out of the $k$ top-ranked items have a score beyond a certain threshold.\n",
    "\n",
    "We can then define the so-called precision@k and recall@k for $k$ recommended items:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "{\\rm precision@k} &=& \\frac{\\rm  Recommended\\ items\\ that\\ are\\ relevant}{\\rm Recommended\\ items}\\\\\n",
    "\\\\\n",
    "{\\rm recall@k} &=& \n",
    "\\frac{\\rm  Recommended\\ items\\ that\\ are\\ relevant}{\\rm Relevant\\ items}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Out of these scores we can define an F1@k score in the usual way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-user diversity\n",
    "\n",
    "We can compare how similar the recommendations are that we make for different users. We would like our recommender to make individual predictions based on user preferences, so predicting always the same top items would not be a good sign.\n",
    "\n",
    "We can measure the inter-user diversity by calculating the cosine-similarity between the $k$ top-ranked items and then average over all user pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intra-user diversity\n",
    "\n",
    "We can measure how similar the $k$ items are that we recommend to a particular user to obtain the intra-user diversity:\n",
    "\n",
    "$$\n",
    "I_u(k) = \\frac{1}{k(k-1)}\\sum_{i\\neq j}{\\rm sim}({\\rm item}_i,{\\rm item}_j)\n",
    "$$\n",
    "\n",
    "\n",
    "Averaging over all users gives the mean intra-similarity of the recommendation list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novelty\n",
    "\n",
    "We can measure the novelty of a recommendation by measuring how popular the recommended items are. For example we could take the degree of each item in the bipartite user-item network and average this degree over the recommendation list for each user before averaging these numbers over all users:\n",
    "\n",
    "$$\n",
    "{\\rm Novelty}(k) = \\frac{1}{M k}\\sum_{u=1}^{M}\\sum_{i\\ {\\rm in\\  top\\  k\\ of\\ u}} {\\rm degree}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage\n",
    "\n",
    "Finally we can measure the so-called coverage, the fraction of all the distinct items $N_{\\rm distinct}$ that appear in all of our top-k recommendation lists:\n",
    "\n",
    "$$\n",
    "{\\rm Coverage}(k) = \\frac{N_{\\rm distinct}}{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline prediction\n",
    "\n",
    "As we are predicting ratings $\\hat{r}_{ui}$ of user $u$ on item $i$, the baseline should be the mean of all ratings, $\\mu$.\n",
    "\n",
    "As we will always be considering a specific user or a specific item, we can determine how much each user's or item's ratings are above the average. \n",
    "\n",
    "Therefore we add a bias term $b_u$ for each user and $b_i$ for each item, so that our baseline is\n",
    "\n",
    "$$\n",
    "{\\rm baseline}_{ui} = \\mu + b_u + b_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Let's say for example that the average rating is $\\mu=3.52$. Our user is very enthusiastic and on average evaluates items better than the average user by $b_u=0.3$. The item is very popular receiving above average ratings with $b_i=0.5$. So we would have a baseline prediction of $4.32$.\n",
    "\n",
    "We will now look at various models which make more accurate predictions based on either similarity or content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity based methods\n",
    "\n",
    "In collaborative filtering, we use similarity measures to infer from past ratings what to recommend in the future. This can be \n",
    "\n",
    "- **item based:** a user who already rated some items positively would like to have similar items recommended in the future\n",
    "- **user based:** users who agree on their item ratings will do so also in the future\n",
    "\n",
    "The term collaborative filtering stems from the fact that multiple users have to share their data to obtain useful recommendations.\n",
    "\n",
    "\n",
    "We can use similarity measures we have already seen frequently:\n",
    "\n",
    "- **Correlation similarity:** \n",
    "\n",
    "$$\n",
    "{\\rm sim}_{\\cos}(u,v) = 1-\\frac{(u-\\bar{u})\\cdot (v-\\bar{v})}{\\|u\\|\\|v\\|}\n",
    "$$\n",
    "\n",
    "- **Cosine similarity**\n",
    "\n",
    "$$\n",
    "{\\rm sim}_{\\cos}(u,v) = 1-\\frac{u\\cdot v}{\\|u\\|\\|v\\|}\n",
    "$$\n",
    "\n",
    "- **Mean squared difference**\n",
    "\n",
    "$$\n",
    "{\\rm msd}(u,v) = \\frac{1}{|I_{uv}|}\\sum_{i\\in I_{uv}}(r_{ui}-r_{vi})^2\n",
    "$$\n",
    "\n",
    "and then\n",
    "\n",
    "$$\n",
    "{\\rm msd\\_sim}(u,v) = \\frac{1}{{\\rm msd}(u,v)+1} \n",
    "$$\n",
    "\n",
    "and similarly for item pairs $i,j$. $|I_{uv}|$ is the number of items rated by both users $u$ and $v$.\n",
    "\n",
    "There exist many more based on the usual distance metrics, but also many specialized for recommendation system requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Consider the following user-item matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_0</th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "      <th>item_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_0  item_1  item_2  item_3  item_4\n",
       "user_0       4       3       2       3       1\n",
       "user_1       4       2       3       1       2\n",
       "user_2       3       4       4       2       2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rui = pd.DataFrame([[4, 3, 2, 3, 1],\n",
    "                    [4, 2, 3, 1, 2],\n",
    "                    [3, 4, 4, 2, 2]],\n",
    "                   columns=[f'item_{i}' for i in range(5)],\n",
    "                   index=[f'user_{u}' for u in range(3)])\n",
    "rui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would be the baseline for each user-item pair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6666666666666665"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = rui.mean().mean()\n",
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_0    1.000000\n",
       "item_1    0.333333\n",
       "item_2    0.333333\n",
       "item_3   -0.666667\n",
       "item_4   -1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi = rui.mean()-mu\n",
    "bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_0   -0.066667\n",
       "user_1   -0.266667\n",
       "user_2    0.333333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bu = rui.mean(axis=1)-mu\n",
    "bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.6        2.93333333 2.93333333 1.93333333 1.6       ]\n",
      " [3.4        2.73333333 2.73333333 1.73333333 1.4       ]\n",
      " [4.         3.33333333 3.33333333 2.33333333 2.        ]]\n"
     ]
    }
   ],
   "source": [
    "baseline = mu + bu.values.reshape(-1, 1) + bi.values.reshape(1, -1)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7333333333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu+bu[1]+bi[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure the user and product similarity using the different measures from the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 2.64575131, 2.82842712],\n",
       "       [2.64575131, 0.        , 2.64575131],\n",
       "       [2.82842712, 2.64575131, 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need Euclidean distance between users for mean squared distance\n",
    "squareform(pdist(rui, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.875      0.88888889]\n",
      " [0.875      0.         0.875     ]\n",
      " [0.88888889 0.875      0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# mean squared distance and similarity between users\n",
    "# subtract from one for dissimilarity\n",
    "print(1-1/(1+squareform(pdist(rui, metric='euclidean')**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.09376219 0.08498198]\n",
      " [0.09376219 0.         0.06900768]\n",
      " [0.08498198 0.06900768 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity between users\n",
    "print(squareform(pdist(rui, metric='cosine')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.07197634 0.07197634 0.08173774 0.06295743]\n",
      " [0.07197634 0.         0.03448276 0.05704583 0.07152331]\n",
      " [0.07197634 0.03448276 0.         0.15630417 0.00962486]\n",
      " [0.08173774 0.05704583 0.15630417 0.         0.19821627]\n",
      " [0.06295743 0.07152331 0.00962486 0.19821627 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity between items (apply to transposed matrix)\n",
    "print(squareform(pdist(rui.T, metric='cosine')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the top-3 items for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain for each user the items with the highest ratings received\n",
    "top_k = 3\n",
    "top_ranked = {}\n",
    "for i in range(rui.shape[0]):\n",
    "    top_ranked[i] = rui.loc[f'user_{i}', :].sort_values(ascending=False)[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: item_0    4\n",
       " item_3    3\n",
       " item_1    3\n",
       " Name: user_0, dtype: int64, 1: item_0    4\n",
       " item_2    3\n",
       " item_4    2\n",
       " Name: user_1, dtype: int64, 2: item_2    4\n",
       " item_1    4\n",
       " item_0    3\n",
       " Name: user_2, dtype: int64}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_0</th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "      <th>item_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_0  item_1  item_2  item_3  item_4\n",
       "user_0       1       1       0       1       0\n",
       "user_1       1       0       1       0       1\n",
       "user_2       1       1       1       0       0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a matrix indicating which items ended up in the top 3 list\n",
    "# start by forming a matrix with the correct shape containing all zeros\n",
    "top_rui = pd.DataFrame(np.zeros_like(\n",
    "    rui), columns=rui.columns, index=rui.index)\n",
    "\n",
    "# now overwrite the positions of top ranked items with 1\n",
    "for key, value in top_ranked.items():\n",
    "    top_rui.loc[f'user_{key}', value.index] = 1\n",
    "top_rui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the inter-user diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.66666667 0.33333333]\n",
      " [0.66666667 0.         0.33333333]\n",
      " [0.33333333 0.33333333 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# determine the distance between different users\n",
    "# cosine similarity looks at overlap in row-entries\n",
    "\n",
    "inter_user = pdist(top_rui, metric='cosine')\n",
    "print(squareform(inter_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44444444444444436"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_user.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the intra-user diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07025330319325973, 0.04818620893963347, 0.059478476270105496]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the distance between the top items proposed to each user\n",
    "# by looking at the similarity in received ratings\n",
    "intra_user = [pdist(rui[top_ranked[i].index.values].T,\n",
    "                    metric='cosine').mean() for i in range(rui.shape[0])]\n",
    "intra_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0593059961343329"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of the intra user similarities across all users\n",
    "np.mean(intra_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine for each item how many times it has been rated\n",
    "degrees = np.array([(rui[f'item_{i}'] > 0).sum()\n",
    "                    for i in range(0, rui.shape[1])])\n",
    "degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average degree of all items in each recommendation list\n",
    "[degrees[top_rui.values[i] > 0].mean()/rui.shape[0]\n",
    " for i in range(rui.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate how many items have been recommended at least once\n",
    "# by calculating the sum along all columns and checking for being different from zero\n",
    "(top_rui.sum() > 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with means\n",
    "\n",
    "In the kNN with means model, we look at either the $k$ most similar users or items and predict based on\n",
    "\n",
    "- user similarity:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu_u+\\frac{\\sum_{v \\in N_i^k(u)}{\\rm sim}(u,v)(r_{vi}-\\mu_v)}{\\sum_{v \\in N_i^k(u)}{\\rm sim}(u,v)}\n",
    "$$\n",
    "\n",
    "- item similarity:\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu_i+\\frac{\\sum_{j \\in N_u^k(i)}{\\rm sim}(i,j)(r_{uj}-\\mu_j)}{\\sum_{j \\in N_u^k(i)}{\\rm sim}(i,j)}\n",
    "$$\n",
    "\n",
    "Here $N_i^k(u)$ denotes the $k$ most similar users to user $u$ who rated item $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "As an example, let's take user similarity (e.g. correlation similarity) and we consider the two nearest neighbors of user $1$.\n",
    "\n",
    "Let's say we have \n",
    "\n",
    "$\\mu_1 = 3$, $\\mu_2 = 2$, $\\mu_3 = 4$,\n",
    "${\\rm sim}(1,2)=0.8$, ${\\rm sim}(1,3)=0.5$, \n",
    "\n",
    "and want to predict for item $1$ with \n",
    "\n",
    "$r_{21}=3.2$ and $r_{31}=3.8$.\n",
    "\n",
    "Then we obtain\n",
    "\n",
    "$$\n",
    "r_{11} = 3 +\\frac{0.8(3.2-2)+0.5(3.8-4)}{0.8+0.5}\n",
    "= 3+\\frac{0.8\\cdot1.2+0.5\\cdot(-0.2)}{1.3}\n",
    "\\approx 3.66\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope-one predictor\n",
    "\n",
    "\n",
    "This scheme makes use of both the information from other users who rated the same item and from the other items rated by the same user to predict a rating:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu_u + \\frac{1}{|R_i(u)|}\\sum_{j \\in R_i(u)}{\\rm dev}(i,j)\n",
    "$$\n",
    "\n",
    "where $R_i(u)$ is the set of items rated by user $u$\n",
    "and the average difference between the ratings of item $i$ and $j$ is\n",
    "\n",
    "$$\n",
    "{\\rm dev}(i,j) = \\frac{1}{|U_{ij}|}\\sum_{u\\in U_{ij}}(r_{ui}-r_{uj})\n",
    "$$\n",
    "\n",
    "and $U_{ij}$ is the set of all users that have rated both items $i$ and $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Consider the following example of ratings\n",
    "\n",
    "|   -     | item 1 | item 2|\n",
    "| ------- |:------:| -----:|\n",
    "| user 1  | 2      | 1.8   |\n",
    "| user 2  | 1      |  ?    |\n",
    "\n",
    "Then we have\n",
    "\n",
    "$\\mu_{\\rm user 2}=1$, $|U_{12}|=1$, $r_{11}=2$, $r_{12}=1.8$ and\n",
    "\n",
    "$$\n",
    "r_{22} = 1+\\frac{1}{1}(1.8-2) = 0.8\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content based filtering\n",
    "\n",
    "### Singular Value decomposition\n",
    "\n",
    "Remember principal component analysis for a data matrix $X$ of shape $n\\times p$. There we looked at the correlation matrix of the data and decomposed it into three matrices. After standard scaling the data matrix, this could be written as \n",
    "\n",
    "$$\n",
    "A = X^T X = V D V^T\n",
    "$$\n",
    "\n",
    "$A$ will be of shape $p\\times p$, $D$ will be a diagonal matrix with the eigenvalues of $A$ on the diagonal, and $V$ is the matrix of eigenvectors of $A$. As the correlation matrix $A$ is symmetric, the eigenvectors are pairwise orthogonal. This is known as the spectral theorem and helped us to decorrelate the data by transforming to the new coordinate system. This entails that the matrix $V^T$ is the inverse matrix of $V$. Such matrices are named orthogonal.\n",
    "\n",
    "Similarly we could have obtained a matrix\n",
    "\n",
    "$$\n",
    "B = X X^T = U^T D' U\n",
    "$$\n",
    "\n",
    "of shape $n\\times n$ with similar properties.\n",
    "\n",
    "This implies that each matrix (square or not, symmetric or not) can be written as a product of three matrices\n",
    "\n",
    "$$\n",
    "X = U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "where $U$ is of shape $n\\times n$, $V$ is of shape $p\\times p$ and $\\Sigma$ of shape $n\\times p$ is a diagonal matrix with the so-called singular values on its diagonal (which are simply the square roots of the eigenvalues). Both $U$ and $V$ are orthogonal matrices.\n",
    "\n",
    "In the same way as for principal component analysis, we can reduce the dimensionality by restricting to the components with the $K$ largest singular values.\n",
    "\n",
    "This is what we are going to do with the user-item matrix. As it is very sparse anyway, we can expect that we won't loose too much information in this way and that we will somehow extract the main tastes and item attributes in this way.\n",
    "\n",
    "That is whereas the rating matrix can be exactly written as\n",
    "\n",
    "$$\n",
    "R = U\\Sigma V^T\n",
    "$$\n",
    "\n",
    "we can approximate it by choosing $\\Sigma$ of shape $K\\times K$ where $K<{\\rm min}(n,p)$ as\n",
    "\n",
    "$$\n",
    "\\hat{R} = U\\Sigma_K V^T\n",
    "$$\n",
    "\n",
    "Isolating global, user and item biases we can then write the rating prediction as \n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu + b_u + b_i + \\sum_{k=1}^K p_{uk}q_{ki}\n",
    "$$\n",
    "\n",
    "Not restricting $K$ will lead to perfect predictions on the training set.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 3, 3],\n",
       "       [1, 2, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2, 3], [1, 3, 3], [1, 2, 1]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.15142284, 0.        , 0.        ],\n",
       "       [0.        , 1.02970897, 0.        ],\n",
       "       [0.        , 0.        , 0.3157475 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD with numpy\n",
    "\n",
    "U, S, VT = np.linalg.svd(A)\n",
    "Sigma = np.diag(S)  # put the returned array S on the diagonal of a matrix\n",
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [1., 3., 3.],\n",
       "       [1., 2., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruct the original matrix\n",
    "(U.dot(Sigma)).dot(VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83697452, 2.07128611, 2.99626008],\n",
       "       [1.20389433, 2.91084317, 3.00467747],\n",
       "       [0.87547428, 2.05445133, 0.9971433 ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restrict to the 2 largest singular values\n",
    "U[:, :].dot(Sigma[:, :2]).dot(VT[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69143694, -0.58448292],\n",
       "       [-4.3529303 ,  0.04953885],\n",
       "       [-2.29462286,  0.84630147]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the individual parts\n",
    "U[:, :].dot(Sigma[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2732291 , -0.66149335, -0.69840704],\n",
       "       [ 0.29365013,  0.63402177, -0.7153922 ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.69143694, -0.58448292],\n",
       "       [ 4.3529303 ,  0.04953885],\n",
       "       [ 2.29462286,  0.84630147]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the same with sklearn\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "svd.fit_transform(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2732291 ,  0.66149335,  0.69840704],\n",
       "       [ 0.29365013,  0.63402177, -0.7153922 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83697452, 2.07128611, 2.99626008],\n",
       "       [1.20389433, 2.91084317, 3.00467747],\n",
       "       [0.87547428, 2.05445133, 0.9971433 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.fit_transform(A).dot(svd.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `TruncatedSVD` to reduce the dimensionality of the rating matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.03234377,  1.61251949],\n",
       "       [ 5.64874945, -0.58221644],\n",
       "       [ 6.86458513, -0.93792662]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=2)\n",
    "rui_truncated = svd.fit_transform(rui)\n",
    "rui_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58324456,  0.49257352,  0.48925006,  0.32468314,  0.26909542],\n",
       "       [ 0.34235824, -0.02057683, -0.59528031,  0.62308202, -0.37386841]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rui_truncated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.07039101, 2.93819228, 1.99142345, 2.96333221, 1.020406  ],\n",
       "       [3.09527579, 2.79440458, 3.11023298, 1.47128512, 1.73772497],\n",
       "       [3.68262503, 3.40061243, 3.91682793, 1.64440985, 2.19788959]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rui_truncated.dot(svd.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.07039101, 2.93819228, 1.99142345, 2.96333221, 1.020406  ],\n",
       "       [3.09527579, 2.79440458, 3.11023298, 1.47128512, 1.73772497],\n",
       "       [3.68262503, 3.40061243, 3.91682793, 1.64440985, 2.19788959]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.inverse_transform(rui_truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18406852651892855"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruction error\n",
    "((rui-svd.inverse_transform(rui_truncated))**2).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Lesson Guide",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
