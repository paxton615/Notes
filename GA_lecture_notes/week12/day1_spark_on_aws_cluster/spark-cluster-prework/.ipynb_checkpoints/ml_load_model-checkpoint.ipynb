{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\"> \n",
    "# Spark Machine Learning Model Loading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps    \n",
    "import warnings         \n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just created a SparkContext\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # we try to create a SparkContext to work locally on all cpus available\n",
    "    sc = ps.SparkContext('local[4]')\n",
    "    sqlContext = SQLContext(sc)\n",
    "    print(\"Just created a SparkContext\")\n",
    "except ValueError:\n",
    "    # give a warning if SparkContext already exists (for use inside pyspark)\n",
    "    warnings.warn(\"SparkContext already exists in this scope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol='prediction',\n",
    "                                labelCol='MEDV',\n",
    "                                metricName='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = ps.sql.SparkSession(sc)\n",
    "\n",
    "spark_df = spark.read.csv(\n",
    "    path='data/boston_housing.csv', \n",
    "    header=True,\n",
    "    mode=\"DROPMALFORMED\",\n",
    "    inferSchema=True,\n",
    "    enforceSchema=False\n",
    "    )\n",
    "(data_train, data_test) = spark_df.randomSplit([0.7, 0.3], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7218117084843778\n",
      "0.7310936297006648\n",
      "0.6934885107911399\n"
     ]
    }
   ],
   "source": [
    "best_model = PipelineModel.load('model-20190907-150636/')\n",
    "\n",
    "predictions = best_model.transform(spark_df)\n",
    "print(evaluator.evaluate(predictions))\n",
    "\n",
    "predictions = best_model.transform(data_train)\n",
    "print(evaluator.evaluate(predictions))\n",
    "\n",
    "predictions = best_model.transform(data_test)\n",
    "print(evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
