{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: least squares loss function\n",
    "\n",
    "---\n",
    "\n",
    "Ordinary least squares regression minimizes the residual sum of squares (RSS) to fit the data:\n",
    "\n",
    "$$ \\text{minimize:}\\; {\\rm RSS} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n \\left(y_i - \\left(\\beta_0 + \\sum_{j=1}^p X_{ij}\\beta_j\\right)\\right)^2 $$\n",
    "\n",
    "where our model predictions for $y$ are based on the sum of the $\\beta_0$ intercept and the products of $\\beta_j$ with $X_{ij}$.\n",
    "\n",
    "Alternatively, in matrix notation using the predictor matrix $X$, the residuals $\\epsilon$ and the vector of beta coefficients $\\beta$ we write the same equation as\n",
    "\n",
    "$$ \\text{minimize:}\\; {\\rm RSS} = \\epsilon^T \\epsilon = (y - X\\beta)^T (y - X\\beta ) $$\n",
    "\n",
    "The derivative with respect to all the beta coefficients becomes\n",
    "\n",
    "$$ \\frac{\\partial RSS}{\\partial \\beta} = -2X^T y + 2X^T X\\beta $$\n",
    "\n",
    "Setting equal to zero and solving for the beta coefficient vector gives\n",
    "\n",
    "$$\\beta = (X^T X)^{-1}X^T y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Ridge penalty\n",
    "\n",
    "---\n",
    "\n",
    "Ridge regression adds the sum of the squared (non-intercept!) $\\beta$ values to the loss function\n",
    "\n",
    "$$ \\text{minimize:}\\; {\\rm RSS+Ridge} = \\sum_{i=1}^n \\left(y_i - \\left(\\beta_0 + \\sum_{j=1}^p x_{ij}\\beta_j\\right)\\right)^2 + \\lambda_2\\sum_{j=1}^p \\beta_j^2$$\n",
    "\n",
    "where $\\beta_j^2$ is the squared coefficient for variable $X_j$.\n",
    "\n",
    "$\\sum_{j=1}^n \\beta_j^2$ is the sum of these squared coefficients for every variable we have in our model. This does **not** include the intercept $\\beta_0$.\n",
    "\n",
    "$\\lambda_2$ is a constant for the _strength_ of the regularization parameter. The higher this value, the greater the impact of this new component in the loss function. If this were zero, then we would revert back to just the least squares loss function. If this were, say, a billion, then the residual sum of squares component would have a much smaller effect on the loss/cost than the regularization term.\n",
    "\n",
    "With the penalty added the RSS is referred to as the **penalized residual sum of squares (PRSS)**. In matrix format the Ridge PRSS is:\n",
    "\n",
    "$$ \\text{Ridge PRSS} = (y - X\\beta)^T (y - X\\beta) + \\lambda_2 \\; \\left\\|\\beta\\right\\|^2_2 $$\n",
    "\n",
    "where $\\left\\|\\beta\\right\\|_2^2$ is the so-called L2-norm of the coefficient vector (again, excluding intercept).\n",
    "\n",
    "The derivative with respect to all the beta coefficients becomes\n",
    "\n",
    "$$ \\frac{\\partial PRSS}{\\partial \\beta} = -2X^T y + 2X^T X\\beta + 2\\lambda_2 \\beta$$\n",
    "\n",
    "Setting equal to zero and solving for the beta coefficient vector gives\n",
    "\n",
    "$$\\beta = (X^T X + \\lambda_2\\mathbb{1})^{-1}X^T y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * in another words, Ridge PRSS = RSS + MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Lasso penalty\n",
    "\n",
    "---\n",
    "\n",
    "The Lasso regression takes a different approach. Instead of adding the sum of _squared_ $\\beta$ coefficients to the RSS, one adds the sum of the _absolute values_ of the $\\beta$ coefficients:\n",
    "\n",
    "$$ \\text{minimize:}\\; {\\rm RSS + Lasso} = \\sum_{i=1}^n \\left(y_i - \\left(\\beta_0 + \\sum_{j=1}^p X_{ij}\\beta_j\\right)\\right)^2 + \\lambda_1\\sum_{j=1}^p |\\beta_j|$$\n",
    "\n",
    "where $|\\beta_j|$ is the absolute value of the $\\beta$ coefficient for variable $X_j$ (this is often called the L1-norm). $\\lambda_1$ is again the strength of the regularization penalty component in the loss function. \n",
    "\n",
    "**In matrix format the Lasso PRSS is:**\n",
    "\n",
    "$$ \\text{Lasso PRSS} = (y - X\\beta)^T (y - X\\beta) + \\lambda_1 \\; \\left\\|\\beta\\right\\|_1 $$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\left\\|\\beta\\right\\|_1=\\sum_{j=1}^p |\\beta_j|$$ \n",
    "\n",
    "Unlike the Ridge, however, there is not a closed-form solution for the Lasso beta coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * Lasso PRSS = RSS + MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
